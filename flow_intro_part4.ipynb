{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 2.2.1+cu121 and Flower 1.7.0\n"
     ]
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import flwr as fl\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize The FLOWER Client Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "\n",
    "NUM_CLIENT = 10\n",
    "EPOCHS_CLIENT = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKER = cpu_count()\n",
    "\n",
    "\n",
    "### Loading The Dataset And Partitioning ###\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    \n",
    "    # image transformation\n",
    "    img_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "    \n",
    "    # loading the torchvision dataset\n",
    "    train_dataset = CIFAR10(\n",
    "        root='./dataset',\n",
    "        train=True,\n",
    "        transform=img_transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    test_dataset = CIFAR10(\n",
    "        root='./dataset',\n",
    "        train=False,\n",
    "        transform=img_transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    # split training dataset into partitions\n",
    "    partition_size = len(train_dataset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    train_part_dataset = random_split(\n",
    "        dataset=train_dataset,\n",
    "        lengths=lengths,\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "    \n",
    "    # create all client train and val dataloaders\n",
    "    train_dataloaders = []\n",
    "    val_dataloaders = []\n",
    "\n",
    "    # split partition into train and val datasets and wrap into torch dataloaders\n",
    "    for dataset in train_part_dataset:\n",
    "        # split the partition\n",
    "        split_dataset = random_split(\n",
    "            dataset=dataset,\n",
    "            lengths=[0.8, 0.2], # train & val dataset split fraction\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        # wrap with torch dataloader and add to dataloader list\n",
    "        partition_train_dl = DataLoader(\n",
    "            dataset=split_dataset[0],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKER\n",
    "        )\n",
    "        partition_val_dl = DataLoader(\n",
    "            dataset=split_dataset[1],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKER\n",
    "        )\n",
    "        train_dataloaders.append(partition_train_dl)\n",
    "        val_dataloaders.append(partition_val_dl)\n",
    "        \n",
    "    # create test dataloader from the test split (Dataset) with transform function\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKER\n",
    "    )\n",
    "\n",
    "    # return all the train (partitioned), val (partitioned) & test dataloaders\n",
    "    return train_dataloaders, val_dataloaders, test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:29<00:00, 5827991.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloaders, val_dataloaders, test_dataloader = load_datasets(NUM_CLIENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining The Model ###\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Creates the TinyVGG architecture for 32*32 Image Data\"\"\"\n",
    "        \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= 10 * 8 * 8, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(self.block2(self.block1(x)))\n",
    "\n",
    "### Train and Test Function For FLOWER Clients\n",
    "    \n",
    "# calculate accuracy\n",
    "def accuracy_fn(y_pred: torch.tensor, y_true: torch.tensor) -> float:\n",
    "    \"\"\"Calculates the accuracy of a model on given predictions\n",
    "\n",
    "    Args:\n",
    "        y_pred: predicted labels\n",
    "        y_true: true labels\n",
    "    \n",
    "    Returns:\n",
    "        A float value which is the calculated accuracy.\n",
    "    \"\"\"\n",
    "    return ((torch.eq(y_pred, y_true).sum().item() / len(y_true)) * 100)\n",
    "\n",
    "# fit the model on training data\n",
    "def train(model: torch.nn.Module,\n",
    "          data_loader: torch.utils.data.DataLoader,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          verbose=False,\n",
    "          loss_fn: torch.nn.Module = None,\n",
    "          optimizer: torch.optim.Optimizer = None) -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for the given epochs.\n",
    "\n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        epochs: Epochs.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        verbose: A boolean value to see the model metrics (loss and accuracy)\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    # optimizer and criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "    model.train() # model in train mode\n",
    "    total_epoch_loss, total_epoch_acc = 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        for X, y in data_loader:\n",
    "            # get data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)        \n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad() # empty param's grad\n",
    "            loss.backward() # backward propagation\n",
    "            optimizer.step() # updata params (take the gradient descent step)\n",
    "\n",
    "            # Metrics\n",
    "            # calculate loss and accuracy per batch\n",
    "            train_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            train_acc += accuracy_fn(y_pred_labels, y)\n",
    "        \n",
    "        # per epoch\n",
    "        train_loss /= len(data_loader.dataset)\n",
    "        train_acc /= len(data_loader)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1} | Train Loss {train_loss:.4f} | Train Acc {train_acc:.2f}\")\n",
    "\n",
    "        # for all epochs\n",
    "        total_epoch_loss += train_loss\n",
    "        total_epoch_acc += train_acc\n",
    "    \n",
    "    return (total_epoch_loss / epochs, total_epoch_acc / epochs)\n",
    "    \n",
    "\n",
    "# test the model on test data\n",
    "def test(model: torch.nn.Module,\n",
    "         data_loader: torch.utils.data.DataLoader,\n",
    "         device: torch.device,\n",
    "         loss_fn: torch.nn.Module=None) -> Tuple[float, float]:\n",
    "    \"\"\"Tests a PyTorch model for the given epochs.\n",
    "\n",
    "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "    a forward pass on a testing dataset.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        data_loader: A DataLoader instance for the model to be tested on.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval() # model in evaluation mode\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # get data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # forward pss\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)\n",
    "\n",
    "            # calculate loss and accuracy per batch\n",
    "            test_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            test_acc += accuracy_fn(y_pred_labels, y)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    test_acc /= len(data_loader)\n",
    "    return (test_loss, test_acc)\n",
    "\n",
    "### Updating Model Parameters (helper functions from client's perspective)\n",
    "\n",
    "# de-serialized & set client parameters\n",
    "def set_parameters(model: nn.Module, parameters: List[np.ndarray]):\n",
    "    # de-serialize the ndarray to tensors\n",
    "    parameters = [torch.from_numpy(np_arr).to(dtype=torch.float32, device=DEVICE) for np_arr in parameters]\n",
    "    # match every weight with its model block\n",
    "    param_dict = zip(model.state_dict().keys(), parameters)\n",
    "    # convert the param_dict to ordered dict and load back into the model\n",
    "    model.load_state_dict(OrderedDict(param_dict), strict=True)\n",
    "\n",
    "# get serialized parameters from client\n",
    "def get_parameters(model: nn.Module) -> List[np.ndarray]:\n",
    "    # serialize the model weights into ndarray and return\n",
    "    return [weights.cpu().numpy() for _, weights in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### client metric aggregation functions\n",
    "from flwr.common import Metrics\n",
    "\n",
    "# aggregate the metrics received from all the client's evaluate function\n",
    "def eval_weighted_avg(metrics: List[Tuple[int, Metrics]]):\n",
    "    #  multiply accuracy with each client's number of samples / or is it batch size??\n",
    "    accuracies = [num_examples * m['test_accuracy'] for num_examples, m in metrics]\n",
    "    num_samples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # aggregate and return the custom metrics (weighted avg)\n",
    "    return {'test_accuracy': sum(accuracies) / sum(num_samples)}\n",
    "\n",
    "# aggregate the metrics received from all the client's fit function\n",
    "def fit_weighted_avg(metrics: List[Tuple[int, Metrics]]):\n",
    "    #  multiply accuracy with each client's number of samples / or is it batch size??\n",
    "    accuracies = [num_examples * m['train_accuracy'] for num_examples, m in metrics]\n",
    "    num_samples = [num_examples for num_examples, _ in metrics]\n",
    "    # for loss\n",
    "    losses = [num_examples * m['train_loss'] for num_examples, m in metrics]\n",
    "\n",
    "    # aggregate and return the custom metrics (weighted avg)\n",
    "    return {'train_loss': sum(losses) / sum(num_samples), 'train_accuracy': sum(accuracies) / sum(num_samples)}\n",
    "\n",
    "\n",
    "### server-side parameter evaluation function\n",
    "# evaluate on the server\n",
    "def eval_server(server_round: int, params: fl.common.NDArray, config: Dict[str, fl.common.Scalar]):\n",
    "    # create server model\n",
    "    model = TinyVGG().to(DEVICE)\n",
    "    # load validation dataloader\n",
    "    val_dl = val_dataloaders[0]\n",
    "    # update model with latest parameters\n",
    "    set_parameters(model=model, parameters=params)\n",
    "    # perform centralized evaluation\n",
    "    loss, accuracy = test(model=model, data_loader=val_dl, device=DEVICE)\n",
    "    print(f'Server round {server_round}: evaluation loss {loss} | accuracy {accuracy}')\n",
    "    return loss, {'accuracy': accuracy}\n",
    "\n",
    "### sending/receiving arbitrary values to/from clients\n",
    "# configure/set client-side params from server side\n",
    "# training configuration from server to client\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict form server to client for each round.\n",
    "\n",
    "    Perform rounds of training with one local epoch.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'server_round': server_round,\n",
    "        'local_epochs': 1\n",
    "    }\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Revisiting FLOWER NumPy Client\n",
    "\n",
    "Whenever a client is called to do some work, `simulation` function calls `client_fn` to create an instance of `NumPyClient` object with client specific dataloaders. However, in reality, Flower wraps the object to make it look like a subclass of `fl.client.Client` and not `fl.client.NumPyClient`.\n",
    "\n",
    "`fl.client.NumPyClient` is just another abstraction over `fl.client.Client`. Therefore, now we'll see how we can directly subclass from `fl.client.Client` and use it.\n",
    "\n",
    "The biggest difference is that `Client` baseclass will expect us to take care of parameter serialization and de-serialization by ourselves.\n",
    "And remember that serialization and de-serialization needs to be done on both client and server side (both will receive and send serialized parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Moving from NumPyClient to Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import(\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Status,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays\n",
    ")\n",
    "\n",
    "class FlowerClient(fl.client.Client):\n",
    "    def __init__(self, cid, model, train_dl, val_dl) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f'[Client {self.cid}] get_parameters')\n",
    "        # get client parameters as a list of ndarrays\n",
    "        ndarray: List[np.ndarray] = get_parameters(self.model)\n",
    "        # serialize ndarrays into a parameter object\n",
    "        parameters = ndarrays_to_parameters(ndarrays=ndarray)\n",
    "        # build and return response/client updates\n",
    "        status = Status(code=Code.OK, message='success')\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=parameters\n",
    "        )\n",
    "    \n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "\n",
    "        # flower_params (de-serialize) -> np.ndarray -> model_params -> np.ndarray -> flower_params (serialize)\n",
    "\n",
    "        print(f'[Client {self.cid}] fit, config: {ins.config}')\n",
    "\n",
    "        # de-serialize received parameters to numpy ndarray\n",
    "        ndarr_parameter = parameters_to_ndarrays(ins.parameters)\n",
    "\n",
    "        # update local model parameters\n",
    "        set_parameters(self.model, ndarr_parameter)\n",
    "\n",
    "        # train & get updated parameters in ndarray\n",
    "        train_loss, train_accuracy = train(\n",
    "            model=self.model,\n",
    "            data_loader=self.train_dl,\n",
    "            epochs=EPOCHS_CLIENT,\n",
    "            device=DEVICE\n",
    "        )\n",
    "        updated_params_ndarr = get_parameters(self.model)\n",
    "\n",
    "        # serialize from ndarray into params object\n",
    "        params_updated = ndarrays_to_parameters(updated_params_ndarr)\n",
    "        \n",
    "        # build and return response/client updates\n",
    "        status = Status(code=Code.OK, message='success')\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=params_updated,\n",
    "            num_examples=len(self.train_dl),\n",
    "            metrics={'train_loss': train_loss,\n",
    "                     'train_accuracy': train_accuracy}\n",
    "        )\n",
    "    \n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        \n",
    "        # flower_params (de-serialize) -> np.ndarray -> model_params -> test()\n",
    "\n",
    "        print(f'[Client {self.cid}] evaluate, config: {ins.config}')\n",
    "\n",
    "        # de-serialize received parameters to numpy ndarray\n",
    "        ndarr_parameter = parameters_to_ndarrays(ins.parameters)\n",
    "\n",
    "        # update local model parameters\n",
    "        set_parameters(self.model, ndarr_parameter)\n",
    "        \n",
    "        # test & get updated parameters in ndarray\n",
    "        test_loss, test_accuracy = test(\n",
    "            model=self.model,\n",
    "            data_loader=self.val_dl,\n",
    "            device=DEVICE\n",
    "        )\n",
    "\n",
    "        # build and return response/client updates\n",
    "        status = Status(code=Code.OK, message='success')\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=test_loss,\n",
    "            num_examples=len(self.val_dl),\n",
    "            metrics={'test_accuracy': test_accuracy}\n",
    "        )\n",
    "    \n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    model = TinyVGG().to(DEVICE)\n",
    "    train_dl = train_dataloaders[int(cid)]\n",
    "    val_dl = val_dataloaders[int(cid)]\n",
    "\n",
    "    return FlowerClient(\n",
    "        cid=cid,\n",
    "        model=model,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-03-29 11:42:44,517 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 11:42:47,660\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-03-29 11:42:48,437 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 7411503513.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'memory': 14823007028.0, 'node:10.255.93.233': 1.0, 'CPU': 16.0}\n",
      "INFO flwr 2024-03-29 11:42:48,437 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-03-29 11:42:48,437 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "INFO flwr 2024-03-29 11:42:48,443 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "INFO flwr 2024-03-29 11:42:48,444 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-03-29 11:42:48,444 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-03-29 11:42:50,196 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-03-29 11:42:50,196 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-03-29 11:42:50,196 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-03-29 11:42:50,197 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] get_parameters\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:42:53,051 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flwr 2024-03-29 11:42:53,052 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-03-29 11:42:53,052 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:42:55,192 | server.py:187 | evaluate_round 1 received 2 results and 0 failures\n",
      "WARNING flwr 2024-03-29 11:42:55,192 | fedavg.py:281 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-03-29 11:42:55,193 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:42:58,005 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
      "DEBUG flwr 2024-03-29 11:42:58,006 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:00,140 | server.py:187 | evaluate_round 2 received 2 results and 0 failures\n",
      "DEBUG flwr 2024-03-29 11:43:00,140 | server.py:222 | fit_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:02,810 | server.py:236 | fit_round 3 received 2 results and 0 failures\n",
      "DEBUG flwr 2024-03-29 11:43:02,811 | server.py:173 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=904736)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:04,936 | server.py:187 | evaluate_round 3 received 2 results and 0 failures\n",
      "INFO flwr 2024-03-29 11:43:04,936 | server.py:153 | FL finished in 14.739556103013456\n",
      "INFO flwr 2024-03-29 11:43:04,937 | app.py:226 | app_fit: losses_distributed [(1, 2.30242875957489), (2, 2.302306652069092), (3, 2.302180121421814)]\n",
      "INFO flwr 2024-03-29 11:43:04,937 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-03-29 11:43:04,937 | app.py:228 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2024-03-29 11:43:04,937 | app.py:229 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-03-29 11:43:04,938 | app.py:230 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.30242875957489\n",
       "\tround 2: 2.302306652069092\n",
       "\tround 3: 2.302180121421814"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Start The Training\n",
    "\n",
    "# client resources (allocate cpus and gpus)\n",
    "client_resources = {'num_cpus': NUM_WORKER//NUM_CLIENT, 'num_gpus': 1 if torch.cuda.is_available() else 0}\n",
    "\n",
    "# start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    # strategy=strategy, # <-- custom strategy\n",
    "    client_resources=client_resources\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Custom Serialization\n",
    "\n",
    "Serialization is an essential step in FL as server and clients rely heavily on internet communication for training purpose.\n",
    "Therefore, writing custom serialization/deserialization functions to convert `ndarray` to `sparse matrices` and vice versa to save bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from typing import cast\n",
    "\n",
    "from flwr.common.typing import NDArray, NDArrays, Parameters\n",
    "\n",
    "# ndarrays -> sparse bytes\n",
    "def ndarrays_to_sparse_parameters(ndarrays: NDArrays) -> Parameters:\n",
    "    \"\"\"Convert NumPy ndarrays to parameters object.\"\"\"\n",
    "    bytes_lst = [ndarray_to_sparse_bytes(ndarray) for ndarray in ndarrays]\n",
    "    return Parameters(\n",
    "        tensors=bytes_lst,\n",
    "        tensor_type='numpy.ndarray'\n",
    "    )\n",
    "\n",
    "# sparse bytes -> ndarrays\n",
    "def sparse_parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n",
    "    \"\"\"Convert parameters object to NumPy ndarrays.\"\"\"\n",
    "    return [sparse_bytes_to_ndarray(bytes) for bytes in parameters.tensors]\n",
    "\n",
    "# convert a single numpy ndarray to a sparse matrix in bytes\n",
    "def ndarray_to_sparse_bytes(ndarray: NDArray) -> bytes:\n",
    "    \"\"\"Serialize a NumPy ndarray to bytes.\"\"\"\n",
    "    \n",
    "    bytes_io = BytesIO() # a file object to store the bytes\n",
    "\n",
    "    if len(ndarray.shape) > 1:\n",
    "        # convert ndarray to a torch sparse matrix\n",
    "        ndarray = torch.tensor(ndarray).to_sparse_csr()\n",
    "        # save to file\n",
    "        np.savez(\n",
    "            file=bytes_io,\n",
    "            crow_indices=ndarray.crow_indices(),\n",
    "            col_indices=ndarray.col_indices(),\n",
    "            values=ndarray.values(),\n",
    "            allow_pickle=False\n",
    "        )\n",
    "    else:\n",
    "        np.save(\n",
    "            file=bytes_io,\n",
    "            arr=ndarray,\n",
    "            allow_pickle=False\n",
    "            )\n",
    "\n",
    "    return bytes_io.getvalue()\n",
    "\n",
    "# convert a sparse matrix in bytes to a numpy ndarray\n",
    "def sparse_bytes_to_ndarray(tensor: bytes) -> NDArray:\n",
    "    \"\"\"Deserialize bytes to a NumPy ndarray\"\"\"\n",
    "\n",
    "    bytes_io = BytesIO(tensor) # write bytes to a file object\n",
    "    # load the sparse matrix objects from file\n",
    "    loader = np.load(bytes_io, allow_pickle=False)\n",
    "\n",
    "    # convert the torch sparse matrix back to ndarray\n",
    "    if 'crow_indices' in loader:\n",
    "        ndarr_deserialized = torch.sparse_csr_tensor(\n",
    "            crow_indices=loader['crow_indices'],\n",
    "            col_indices=loader['col_indices'],\n",
    "            values=loader['values']\n",
    "        ).to_dense().numpy()\n",
    "    else:\n",
    "        ndarr_deserialized = loader\n",
    "    \n",
    "    return cast(NDArray, ndarr_deserialized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client Side Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import(\n",
    "    Code,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    GetParametersIns,\n",
    "    GetParametersRes,\n",
    "    Status,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays\n",
    ")\n",
    "\n",
    "class FlowerClient(fl.client.Client):\n",
    "    def __init__(self, cid, model, train_dl, val_dl) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f'[Client {self.cid}] get_parameters')\n",
    "        \n",
    "        # get client parameters as a list of ndarrays\n",
    "        ndarrays: List[np.ndarray] = get_parameters(self.model)\n",
    "        \n",
    "        # serialize ndarrays into a Parameter object (containing sparse matrix bytes)\n",
    "        sparse_parameters = ndarrays_to_sparse_parameters(ndarrays)\n",
    "        \n",
    "        # build and return response/client updates\n",
    "        status = Status(code=Code.OK, message='success')\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=sparse_parameters\n",
    "        )\n",
    "    \n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "\n",
    "        # flower_params (de-serialize) -> np.ndarray -> model_params -> np.ndarray -> flower_params (serialize)\n",
    "\n",
    "        print(f'[Client {self.cid}] fit, config: {ins.config}')\n",
    "\n",
    "        # de-serialize received parameters to numpy ndarray\n",
    "        ndarr_parameter = sparse_parameters_to_ndarrays(ins.parameters)\n",
    "\n",
    "        # update local model parameters\n",
    "        set_parameters(self.model, ndarr_parameter)\n",
    "\n",
    "        # train & get updated parameters in ndarray\n",
    "        train_loss, train_accuracy = train(\n",
    "            model=self.model,\n",
    "            data_loader=self.train_dl,\n",
    "            epochs=EPOCHS_CLIENT,\n",
    "            device=DEVICE\n",
    "        )\n",
    "        updated_params_ndarr = get_parameters(self.model)\n",
    "\n",
    "        # serialize from ndarray into params object\n",
    "        params_updated = ndarrays_to_sparse_parameters(updated_params_ndarr)\n",
    "        \n",
    "        # build and return response/client updates\n",
    "        status = Status(code=Code.OK, message='success')\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=params_updated,\n",
    "            num_examples=len(self.train_dl),\n",
    "            metrics={'train_loss': train_loss,\n",
    "                     'train_accuracy': train_accuracy}\n",
    "        )\n",
    "    \n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        \n",
    "        # flower_params (de-serialize) -> np.ndarray -> model_params -> test()\n",
    "\n",
    "        print(f'[Client {self.cid}] evaluate, config: {ins.config}')\n",
    "\n",
    "        # de-serialize received parameters to numpy ndarray\n",
    "        ndarr_parameter = sparse_parameters_to_ndarrays(ins.parameters)\n",
    "\n",
    "        # update local model parameters\n",
    "        set_parameters(self.model, ndarr_parameter)\n",
    "        \n",
    "        # test & get updated parameters in ndarray\n",
    "        test_loss, test_accuracy = test(\n",
    "            model=self.model,\n",
    "            data_loader=self.val_dl,\n",
    "            device=DEVICE\n",
    "        )\n",
    "\n",
    "        # build and return response/client updates\n",
    "        status = Status(code=Code.OK, message='success')\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=test_loss,\n",
    "            num_examples=len(self.val_dl),\n",
    "            metrics={'test_accuracy': test_accuracy}\n",
    "        )\n",
    "    \n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    model = TinyVGG().to(DEVICE)\n",
    "    train_dl = train_dataloaders[int(cid)]\n",
    "    val_dl = val_dataloaders[int(cid)]\n",
    "\n",
    "    return FlowerClient(\n",
    "        cid=cid,\n",
    "        model=model,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Server Side Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import WARNING\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from flwr.common import FitRes, MetricsAggregationFn, NDArrays, Parameters, Scalar\n",
    "from flwr.common.logger import log\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server.strategy.aggregate import aggregate\n",
    "\n",
    "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\n",
    "Setting `min_available_clients` lower than `min_fit_clients` or\n",
    "`min_evaluate_clients` can cause the server to fail when there are too few clients\n",
    "connected to the server. `min_available_clients` must be set to a value larger\n",
    "than or equal to the values of `min_fit_clients` and `min_evaluate_clients`.\n",
    "\"\"\"\n",
    "\n",
    "class FedSparse(fl.server.strategy.FedAvg):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, Dict[str, Scalar]],\n",
    "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Custom FedAvg strategy with sparse matrices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fraction_fit : float, optional\n",
    "            Fraction of clients used during training. Defaults to 0.1.\n",
    "        fraction_evaluate : float, optional\n",
    "            Fraction of clients used during validation. Defaults to 0.1.\n",
    "        min_fit_clients : int, optional\n",
    "            Minimum number of clients used during training. Defaults to 2.\n",
    "        min_evaluate_clients : int, optional\n",
    "            Minimum number of clients used during validation. Defaults to 2.\n",
    "        min_available_clients : int, optional\n",
    "            Minimum number of total clients in the system. Defaults to 2.\n",
    "        evaluate_fn : Optional[Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]]\n",
    "            Optional function used for validation. Defaults to None.\n",
    "        on_fit_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
    "            Function used to configure training. Defaults to None.\n",
    "        on_evaluate_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
    "            Function used to configure validation. Defaults to None.\n",
    "        accept_failures : bool, optional\n",
    "            Whether or not accept rounds containing failures. Defaults to True.\n",
    "        initial_parameters : Parameters, optional\n",
    "            Initial global model parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "            min_fit_clients > min_available_clients\n",
    "            or min_evaluate_clients > min_available_clients\n",
    "        ):\n",
    "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
    "\n",
    "        super().__init__(\n",
    "            fraction_fit=fraction_fit,\n",
    "            fraction_evaluate=fraction_evaluate,\n",
    "            min_fit_clients=min_fit_clients,\n",
    "            min_evaluate_clients=min_evaluate_clients,\n",
    "            min_available_clients=min_available_clients,\n",
    "            evaluate_fn=evaluate_fn,\n",
    "            on_fit_config_fn=on_fit_config_fn,\n",
    "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "            accept_failures=accept_failures,\n",
    "            initial_parameters=initial_parameters,\n",
    "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        )\n",
    "\n",
    "    def aggregate_fit(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            results: List[Tuple[ClientProxy | FitRes]],\n",
    "            failures: List[Tuple[ClientProxy | FitRes] | BaseException]\n",
    "            ) -> Tuple[Parameters | None | Dict[str, bool | bytes | float | int | str]]:\n",
    "        \"\"\"Aggregate the fit results using weighted average\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        # do not aggregate if there are failures and they are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "        \n",
    "        # deserialize and get the updated parameter & client dataset size\n",
    "        weights_results = [(sparse_parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples) for _, fit_res in results]\n",
    "        # aggregate the parameters and serialize\n",
    "        parameters_aggregated = ndarrays_to_sparse_parameters(aggregate(weights_results))\n",
    "        \n",
    "        # aggregate custom metrics if aggregration_fn was provided\n",
    "        metrics_aggregated = {}\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(fit_res.num_examples, fit_res.metrics) for _, fit_res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "        elif server_round == 1: # log warning once\n",
    "            log(WARNING, 'No fit_metrics_aggregation_fn was provided')\n",
    "\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "    \n",
    "    # server side evaluation\n",
    "    def evaluate(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            parameters: Parameters,\n",
    "            ) -> Tuple[float | Dict[str, bool | bytes | float | int | str]] | None:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "\n",
    "        if self.evaluate_fn is None: # no evaluation function provided\n",
    "            return None\n",
    "        \n",
    "        # deserialized the parameters\n",
    "        parameters_ndarrays = sparse_parameters_to_ndarrays(parameters)\n",
    "\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        \n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-03-29 11:43:05,013 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 11:43:08,295\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-03-29 11:43:09,108 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 7404576768.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'memory': 14809153536.0, 'node:10.255.93.233': 1.0, 'CPU': 16.0}\n",
      "INFO flwr 2024-03-29 11:43:09,108 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-03-29 11:43:09,108 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "INFO flwr 2024-03-29 11:43:09,114 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "INFO flwr 2024-03-29 11:43:09,114 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-03-29 11:43:09,115 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-03-29 11:43:09,115 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-03-29 11:43:09,524 | server.py:94 | initial parameters (loss, other metrics): 2.3025579166412355, {'accuracy': 11.03515625}\n",
      "INFO flwr 2024-03-29 11:43:09,524 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-03-29 11:43:09,525 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 0: evaluation loss 2.3025579166412355 | accuracy 11.03515625\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m /tmp/ipykernel_791708/366104501.py:28: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 0] fit, config: {'server_round': 1, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:13,374 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
      "INFO flwr 2024-03-29 11:43:13,779 | server.py:125 | fit progress: (1, 2.3025342025756834, {'accuracy': 10.9375}, 4.254866642993875)\n",
      "DEBUG flwr 2024-03-29 11:43:13,780 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 1: evaluation loss 2.3025342025756834 | accuracy 10.9375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:15,889 | server.py:187 | evaluate_round 1 received 2 results and 0 failures\n",
      "DEBUG flwr 2024-03-29 11:43:15,890 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 1] fit, config: {'server_round': 2, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 0] fit, config: {'server_round': 2, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:18,496 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
      "INFO flwr 2024-03-29 11:43:18,890 | server.py:125 | fit progress: (2, 2.3025121841430662, {'accuracy': 10.9375}, 9.365643000928685)\n",
      "DEBUG flwr 2024-03-29 11:43:18,891 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 2: evaluation loss 2.3025121841430662 | accuracy 10.9375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:20,979 | server.py:187 | evaluate_round 2 received 2 results and 0 failures\n",
      "DEBUG flwr 2024-03-29 11:43:20,979 | server.py:222 | fit_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 1] fit, config: {'server_round': 3, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 0] fit, config: {'server_round': 3, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:23,793 | server.py:236 | fit_round 3 received 2 results and 0 failures\n",
      "INFO flwr 2024-03-29 11:43:24,250 | server.py:125 | fit progress: (3, 2.3024918632507325, {'accuracy': 10.9375}, 14.725478978944011)\n",
      "DEBUG flwr 2024-03-29 11:43:24,251 | server.py:173 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 3: evaluation loss 2.3024918632507325 | accuracy 10.9375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=908911)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-03-29 11:43:26,326 | server.py:187 | evaluate_round 3 received 2 results and 0 failures\n",
      "INFO flwr 2024-03-29 11:43:26,327 | server.py:153 | FL finished in 16.802086564945057\n",
      "INFO flwr 2024-03-29 11:43:26,327 | app.py:226 | app_fit: losses_distributed [(1, 2.3029259300231932), (2, 2.3028764419555663), (3, 2.3028296508789063)]\n",
      "INFO flwr 2024-03-29 11:43:26,327 | app.py:227 | app_fit: metrics_distributed_fit {'train_loss': [(1, 2.302782864570618), (2, 2.3027063970565798), (3, 2.3026384296417235)], 'train_accuracy': [(1, 10.2375), (2, 10.2625), (3, 10.2375)]}\n",
      "INFO flwr 2024-03-29 11:43:26,327 | app.py:228 | app_fit: metrics_distributed {'test_accuracy': [(1, 10.3515625), (2, 10.302734375), (3, 10.302734375)]}\n",
      "INFO flwr 2024-03-29 11:43:26,328 | app.py:229 | app_fit: losses_centralized [(0, 2.3025579166412355), (1, 2.3025342025756834), (2, 2.3025121841430662), (3, 2.3024918632507325)]\n",
      "INFO flwr 2024-03-29 11:43:26,328 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 11.03515625), (1, 10.9375), (2, 10.9375), (3, 10.9375)]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.3029259300231932\n",
       "\tround 2: 2.3028764419555663\n",
       "\tround 3: 2.3028296508789063\n",
       "History (loss, centralized):\n",
       "\tround 0: 2.3025579166412355\n",
       "\tround 1: 2.3025342025756834\n",
       "\tround 2: 2.3025121841430662\n",
       "\tround 3: 2.3024918632507325\n",
       "History (metrics, distributed, fit):\n",
       "{'train_loss': [(1, 2.302782864570618), (2, 2.3027063970565798), (3, 2.3026384296417235)], 'train_accuracy': [(1, 10.2375), (2, 10.2625), (3, 10.2375)]}History (metrics, distributed, evaluate):\n",
       "{'test_accuracy': [(1, 10.3515625), (2, 10.302734375), (3, 10.302734375)]}History (metrics, centralized):\n",
       "{'accuracy': [(0, 11.03515625), (1, 10.9375), (2, 10.9375), (3, 10.9375)]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Start The Training\n",
    "\n",
    "params = get_parameters(TinyVGG())\n",
    "\n",
    "strategy = FedSparse(\n",
    "    # fraction_fit=1.0, # C: fraction of client to choose for training\n",
    "    # fraction_evaluate=0.5, # fraction of client to choose for evaluation\n",
    "    # min_fit_clients=10, # minimum clients needed for training\n",
    "    # min_evaluate_clients=5, # minimum clients needed for evaluation\n",
    "    # min_available_clients=10, # wait till given client are available\n",
    "    evaluate_metrics_aggregation_fn=eval_weighted_avg, # aggregate the val metrics of clients\n",
    "    fit_metrics_aggregation_fn=fit_weighted_avg, # aggregate the train metrics of clients\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params), # init parameters passed\n",
    "    evaluate_fn=eval_server, # server evaluation function passed here\n",
    "    on_fit_config_fn=fit_config, # client fit config send from server/strategy\n",
    ")\n",
    "\n",
    "# client resources (allocate cpus and gpus)\n",
    "client_resources = {'num_cpus': NUM_WORKER//NUM_CLIENT, 'num_gpus': 1 if torch.cuda.is_available() else 0}\n",
    "\n",
    "# start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=strategy, # <-- our custom strategy FedSparse\n",
    "    client_resources=client_resources\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
