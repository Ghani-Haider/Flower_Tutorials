{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 2.2.1+cu121 and Flower 1.7.0\n"
     ]
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchinfo import summary\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use A Federated Learning Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "\n",
    "NUM_CLIENT = 10\n",
    "EPOCHS_CLIENT = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKER = cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Torchvision CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading The Dataset And Partitioning ###\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    \n",
    "    # image transformation\n",
    "    img_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "    \n",
    "    # loading the torchvision dataset\n",
    "    train_dataset = CIFAR10(\n",
    "        root='./dataset',\n",
    "        train=True,\n",
    "        transform=img_transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    test_dataset = CIFAR10(\n",
    "        root='./dataset',\n",
    "        train=False,\n",
    "        transform=img_transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    # split training dataset into partitions\n",
    "    partition_size = len(train_dataset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    train_part_dataset = random_split(\n",
    "        dataset=train_dataset,\n",
    "        lengths=lengths,\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "    \n",
    "    # create all client train and val dataloaders\n",
    "    train_dataloaders = []\n",
    "    val_dataloaders = []\n",
    "\n",
    "    # split partition into train and val datasets and wrap into torch dataloaders\n",
    "    for dataset in train_part_dataset:\n",
    "        # split the partition\n",
    "        split_dataset = random_split(\n",
    "            dataset=dataset,\n",
    "            lengths=[0.8, 0.2], # train & val dataset split fraction\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        # wrap with torch dataloader and add to dataloader list\n",
    "        partition_train_dl = DataLoader(\n",
    "            dataset=split_dataset[0],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKER\n",
    "        )\n",
    "        partition_val_dl = DataLoader(\n",
    "            dataset=split_dataset[1],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKER\n",
    "        )\n",
    "        train_dataloaders.append(partition_train_dl)\n",
    "        val_dataloaders.append(partition_val_dl)\n",
    "        \n",
    "    # create test dataloader from the test split (Dataset) with transform function\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKER\n",
    "    )\n",
    "\n",
    "    # return all the train (partitioned), val (partitioned) & test dataloaders\n",
    "    return train_dataloaders, val_dataloaders, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:23<00:00, 7341435.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloaders, val_dataloaders, test_dataloader = load_datasets(NUM_CLIENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training & Eval Client Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining The Model ###\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Creates the TinyVGG architecture for 32*32 Image Data\"\"\"\n",
    "        \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= 10 * 8 * 8, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(self.block2(self.block1(x)))\n",
    "\n",
    "### Train and Test Function For FLOWER Clients\n",
    "    \n",
    "# calculate accuracy\n",
    "def accuracy_fn(y_pred: torch.tensor, y_true: torch.tensor) -> float:\n",
    "    \"\"\"Calculates the accuracy of a model on given predictions\n",
    "\n",
    "    Args:\n",
    "        y_pred: predicted labels\n",
    "        y_true: true labels\n",
    "    \n",
    "    Returns:\n",
    "        A float value which is the calculated accuracy.\n",
    "    \"\"\"\n",
    "    return ((torch.eq(y_pred, y_true).sum().item() / len(y_true)) * 100)\n",
    "\n",
    "# fit the model on training data\n",
    "def train(model: torch.nn.Module,\n",
    "          data_loader: torch.utils.data.DataLoader,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          verbose=False,\n",
    "          loss_fn: torch.nn.Module = None,\n",
    "          optimizer: torch.optim.Optimizer = None) -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for the given epochs.\n",
    "\n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        epochs: Epochs.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        verbose: A boolean value to see the model metrics (loss and accuracy)\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    # optimizer and criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "    model.train() # model in train mode\n",
    "    total_epoch_loss, total_epoch_acc = 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        for X, y in data_loader:\n",
    "            # get data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)        \n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad() # empty param's grad\n",
    "            loss.backward() # backward propagation\n",
    "            optimizer.step() # updata params (take the gradient descent step)\n",
    "\n",
    "            # Metrics\n",
    "            # calculate loss and accuracy per batch\n",
    "            train_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            train_acc += accuracy_fn(y_pred_labels, y)\n",
    "        \n",
    "        # per epoch\n",
    "        train_loss /= len(data_loader.dataset)\n",
    "        train_acc /= len(data_loader)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1} | Train Loss {train_loss:.4f} | Train Acc {train_acc:.2f}\")\n",
    "\n",
    "        # for all epochs\n",
    "        total_epoch_loss += train_loss\n",
    "        total_epoch_acc += train_acc\n",
    "    \n",
    "    return (total_epoch_loss / epochs, total_epoch_acc / epochs)\n",
    "    \n",
    "\n",
    "# test the model on test data\n",
    "def test(model: torch.nn.Module,\n",
    "         data_loader: torch.utils.data.DataLoader,\n",
    "         device: torch.device,\n",
    "         loss_fn: torch.nn.Module=None) -> Tuple[float, float]:\n",
    "    \"\"\"Tests a PyTorch model for the given epochs.\n",
    "\n",
    "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "    a forward pass on a testing dataset.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        data_loader: A DataLoader instance for the model to be tested on.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval() # model in evaluation mode\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # get data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # forward pss\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)\n",
    "\n",
    "            # calculate loss and accuracy per batch\n",
    "            test_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            test_acc += accuracy_fn(y_pred_labels, y)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    test_acc /= len(data_loader)\n",
    "    return (test_loss, test_acc)\n",
    "\n",
    "### Updating Model Parameters (helper functions from client's perspective)\n",
    "\n",
    "# set client paramters\n",
    "def set_parameters(model: nn.Module, parameters: List[np.ndarray]):\n",
    "    # de-serialize the ndarray to tensors\n",
    "    parameters = [torch.from_numpy(np_arr).to(dtype=torch.float32, device=DEVICE) for np_arr in parameters]\n",
    "    # match every weight with its model block\n",
    "    param_dict = zip(model.state_dict().keys(), parameters)\n",
    "    # convert the param_dict to ordered dict and load back into the model\n",
    "    model.load_state_dict(OrderedDict(param_dict), strict=True)\n",
    "\n",
    "# get parameters from client\n",
    "def get_parameters(model: nn.Module) -> List[np.ndarray]:\n",
    "    # serialize the model weights into ndarray and return\n",
    "    return [weights.cpu().numpy() for _, weights in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing FLOWER Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing A FLOWER Client using NumPyClient\n",
    "\n",
    "class CustomClient(fl.client.NumPyClient):\n",
    "    \"\"\"A custom client implementation representing an organization with model and data\"\"\"\n",
    "\n",
    "    # pass a model, train and test dataloader\n",
    "    def __init__(self, client_id: int, model, train_dataloader, val_dataloader) -> None:\n",
    "        super().__init__()\n",
    "        self.cid = client_id\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "\n",
    "    # return the current local model parameters to server\n",
    "    def get_parameters(self, config):\n",
    "        print(f'[Client {self.cid}] get_parameters')\n",
    "        return get_parameters(self.model)\n",
    "    \n",
    "    # receive global model parameters, train and return the updated parameters with other metrics/arbitrary values\n",
    "    def fit(self, parameters, config):\n",
    "        print(f'[Client {self.cid}] fit, config: {config}')\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = train(model=self.model, data_loader=self.train_dataloader, epochs=EPOCHS_CLIENT, device=DEVICE)\n",
    "        return get_parameters(self.model), len(self.train_dataloader), {'loss': loss, 'accuracy': accuracy} # updated parameters, num_batches, metrics\n",
    "    \n",
    "    # receive global model parameters, evaluate and return the metrics/arbitrary values\n",
    "    def evaluate(self, parameters, config) -> Tuple[float | int | Dict[str, bool | bytes | float | int | str]]:\n",
    "        print(f'[Client {self.cid}] evaluate, config: {config}')\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = test(model=self.model, data_loader=self.val_dataloader, device=DEVICE)\n",
    "        return float(loss), len(self.val_dataloader), {'accuracy': accuracy} # loss, num_batches, metrics\n",
    "    \n",
    "### client_fun: To create a CustomClient instance on demand when requested from FLOWER Framework\n",
    "\n",
    "def client_fn(client_id: str) -> CustomClient:\n",
    "    \"\"\"Create a FLOWER client representing a single organization\n",
    "\n",
    "    Creates an instance of CustomClient based on the client_id provided\n",
    "    to load client specific data partition.\n",
    "\n",
    "    Args:\n",
    "        client_id: An str to load a specific client.\n",
    "\n",
    "    Returns:\n",
    "        A CustomClient (fl.client.NumPyClient) instance representing a FLOWER client.\n",
    "    \"\"\"\n",
    "\n",
    "    # create an instance of the model\n",
    "    model = TinyVGG().to(DEVICE)\n",
    "\n",
    "    # load the client specific dataloaders\n",
    "    train_dl = train_dataloaders[int(client_id)]\n",
    "    val_dl = val_dataloaders[int(client_id)]\n",
    "\n",
    "    # create client instance, convert object to Client type and return\n",
    "    return CustomClient(client_id=int(client_id), model=model, train_dataloader=train_dl, val_dataloader=val_dl).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### client metric aggregation functions\n",
    "\n",
    "# aggregate the metrics received from all the client's evaluate function\n",
    "def eval_weighted_avg(metrics: List[Tuple[int, Metrics]]):\n",
    "    #  multiply accuracy with each client's number of samples / or is it batch size??\n",
    "    accuracies = [num_examples * m['accuracy'] for num_examples, m in metrics]\n",
    "    num_samples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # aggregate and return the custom metrics (weighted avg)\n",
    "    return {'test_accuracy': sum(accuracies) / sum(num_samples)}\n",
    "\n",
    "# aggregate the metrics received from all the client's fit function\n",
    "def fit_weighted_avg(metrics: List[Tuple[int, Metrics]]):\n",
    "    #  multiply accuracy with each client's number of samples / or is it batch size??\n",
    "    accuracies = [num_examples * m['accuracy'] for num_examples, m in metrics]\n",
    "    num_samples = [num_examples for num_examples, _ in metrics]\n",
    "    # for loss\n",
    "    losses = [num_examples * m['loss'] for num_examples, m in metrics]\n",
    "\n",
    "    # aggregate and return the custom metrics (weighted avg)\n",
    "    return {'train_loss': sum(losses) / sum(num_samples), 'train_accuracy': sum(accuracies) / sum(num_samples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizations\n",
    "\n",
    "1. Server-side parameter initialization: initialized model params at server\n",
    "2. Changing strategy: FedAvg, FedAdagrad etc\n",
    "3. Server-side evaluation: test/val at server\n",
    "4. Sending/receiving arbitrary values to/from clients: configure/set client-side params from server side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. server-side initialization\n",
    "## get serialized (numpy version) parameters of the model\n",
    "params = get_parameters(TinyVGG())\n",
    "## pass the parameters to the strategy\n",
    "# strategy = fl.server.strategy.FedAvg(\n",
    "#     fraction_fit=1.0, # C: fraction of client to choose for training\n",
    "#     fraction_evaluate=0.5, # fraction of client to choose for evaluation\n",
    "#     min_fit_clients=10, # minimum clients needed for training\n",
    "#     min_evaluate_clients=5, # minimum clients needed for evaluation\n",
    "#     min_available_clients=10, # wait till given client are available\n",
    "#     evaluate_metrics_aggregation_fn=eval_weighted_avg, # aggregate the val metrics of clients\n",
    "#     fit_metrics_aggregation_fn=fit_weighted_avg, # aggregate the train metrics of clients\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(params), # <-- passed parameters\n",
    "# )\n",
    "\n",
    "### 2. changing strategy to FedAdagrad\n",
    "# strategy = fl.server.strategy.FedAdagrad(\n",
    "#     fraction_fit=1.0, # C: fraction of client to choose for training\n",
    "#     fraction_evaluate=0.5, # fraction of client to choose for evaluation\n",
    "#     min_fit_clients=10, # minimum clients needed for training\n",
    "#     min_evaluate_clients=5, # minimum clients needed for evaluation\n",
    "#     min_available_clients=10, # wait till given client are available\n",
    "#     evaluate_metrics_aggregation_fn=eval_weighted_avg, # aggregate the metrics of clients\n",
    "#     fit_metrics_aggregation_fn=fit_weighted_avg, # aggregate the metrics of clients\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(params), # initial parameters\n",
    "# )\n",
    "\n",
    "### 3. Server-side parameter evaluation\n",
    "def eval_server(server_round: int, params: fl.common.NDArray, config: Dict[str, fl.common.Scalar]):\n",
    "    # create server model\n",
    "    model = TinyVGG().to(DEVICE)\n",
    "    # load validation dataloader\n",
    "    val_dl = val_dataloaders[0]\n",
    "    # update model with latest parameters\n",
    "    set_parameters(model=model, parameters=params)\n",
    "    # perform centralized evaluation\n",
    "    loss, accuracy = test(model=model, data_loader=val_dl, device=DEVICE)\n",
    "    print(f'Server round {server_round}: evaluation loss {loss} | accuracy {accuracy}')\n",
    "    return loss, {'accuracy': accuracy}\n",
    "\n",
    "# strategy = fl.server.strategy.FedAvg(\n",
    "#     fraction_fit=1.0, # C: fraction of client to choose for training\n",
    "#     fraction_evaluate=0.5, # fraction of client to choose for evaluation\n",
    "#     min_fit_clients=10, # minimum clients needed for training\n",
    "#     min_evaluate_clients=5, # minimum clients needed for evaluation\n",
    "#     min_available_clients=10, # wait till given client are available\n",
    "#     # fit_metrics_aggregation_fn=fit_weighted_avg, # aggregate the metrics of clients\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(params), # init parameters passed\n",
    "#     evaluate_fn=eval_server, # <-- server evaluation function passed here\n",
    "# )\n",
    "\n",
    "### 4: Sending/receiving arbitrary values to/from clients: configure/set client-side params from server side\n",
    "\n",
    "# FLOWER Client with client specific epochs send from server through config parameter in fit and eval functions\n",
    "class CustomClient(fl.client.NumPyClient):\n",
    "    \"\"\"A custom client implementation representing an organization with model and data\"\"\"\n",
    "\n",
    "    # pass a model, train and test dataloader\n",
    "    def __init__(self, client_id: int, model, train_dataloader, val_dataloader) -> None:\n",
    "        super().__init__()\n",
    "        self.cid = client_id\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "\n",
    "    # return the current local model parameters to server\n",
    "    def get_parameters(self, config):\n",
    "        print(f'[Client {self.cid}] get_parameters')\n",
    "        return get_parameters(self.model)\n",
    "    \n",
    "    # receive global model parameters, train and return the updated parameters with other metrics\n",
    "    def fit(self, parameters, config):\n",
    "        # get client specific epochs from config\n",
    "        server_round = config['server_round']\n",
    "        client_epochs = config['local_epochs']\n",
    "\n",
    "        # use the values provided by config\n",
    "        print(f'[Client {self.cid}] round {server_round} fit, config: {config}')\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = train(model=self.model, data_loader=self.train_dataloader, epochs=client_epochs, device=DEVICE)\n",
    "        return get_parameters(self.model), len(self.train_dataloader), {'loss': loss, 'accuracy': accuracy} # updated parameters, num_batches, metrics\n",
    "    \n",
    "    # receive global model parameters, evaluate and return the metrics\n",
    "    def evaluate(self, parameters, config) -> Tuple[float | int | Dict[str, bool | bytes | float | int | str]]:\n",
    "        print(f'[Client {self.cid}] evaluate, config: {config}')\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = test(model=self.model, data_loader=self.val_dataloader, device=DEVICE)\n",
    "        return float(loss), len(self.val_dataloader), {'accuracy': accuracy} # loss, num_batches, metrics\n",
    "\n",
    "# training configuration from server to client\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'server_round': server_round,\n",
    "        'local_epochs': 1 if server_round < 2 else 2\n",
    "    }\n",
    "    return config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0, # C: fraction of client to choose for training\n",
    "    fraction_evaluate=0.5, # fraction of client to choose for evaluation\n",
    "    min_fit_clients=10, # minimum clients needed for training\n",
    "    min_evaluate_clients=5, # minimum clients needed for evaluation\n",
    "    min_available_clients=10, # wait till given client are available\n",
    "    # evaluate_metrics_aggregation_fn=eval_weighted_avg, # aggregate the val metrics of clients\n",
    "    # fit_metrics_aggregation_fn=fit_weighted_avg, # aggregate the train metrics of clients\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params), # init parameters passed\n",
    "    evaluate_fn=eval_server, # server evaluation function passed here\n",
    "    on_fit_config_fn=fit_config, # <-- client fit config send from server/strategy\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-04-02 15:34:13,429 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 15:34:15,084\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-04-02 15:34:15,862 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'accelerator_type:G': 1.0, 'GPU': 1.0, 'object_store_memory': 6315348787.0, 'node:10.255.93.233': 1.0, 'memory': 12630697575.0, 'CPU': 16.0}\n",
      "INFO flwr 2024-04-02 15:34:15,863 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-04-02 15:34:15,863 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "INFO flwr 2024-04-02 15:34:15,869 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "INFO flwr 2024-04-02 15:34:15,869 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-04-02 15:34:15,869 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-04-02 15:34:15,870 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-04-02 15:34:16,483 | server.py:94 | initial parameters (loss, other metrics): 2.3042768020629882, {'accuracy': 8.3984375}\n",
      "INFO flwr 2024-04-02 15:34:16,484 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-04-02 15:34:16,484 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 0: evaluation loss 2.3042768020629882 | accuracy 8.3984375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 7] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 6] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 5] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 8] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 9] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 1] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 0] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 3] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 4] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 2] round 1 fit, config: {'server_round': 1, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-04-02 15:34:30,794 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2024-04-02 15:34:30,799 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2024-04-02 15:34:31,171 | server.py:125 | fit progress: (1, 2.3041712799072265, {'accuracy': 8.3984375}, 14.68658795603551)\n",
      "DEBUG flwr 2024-04-02 15:34:31,171 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 1: evaluation loss 2.3041712799072265 | accuracy 8.3984375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-04-02 15:34:36,277 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
      "WARNING flwr 2024-04-02 15:34:36,278 | fedavg.py:281 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-04-02 15:34:36,278 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 3] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 7] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 4] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 6] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 8] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 0] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 9] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 5] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 1] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 2] round 2 fit, config: {'server_round': 2, 'local_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-04-02 15:34:56,663 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
      "INFO flwr 2024-04-02 15:34:57,044 | server.py:125 | fit progress: (2, 2.303984405517578, {'accuracy': 8.3984375}, 40.55921363201924)\n",
      "DEBUG flwr 2024-04-02 15:34:57,044 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 2: evaluation loss 2.303984405517578 | accuracy 8.3984375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-04-02 15:35:02,587 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-04-02 15:35:02,588 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 4] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 9] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 5] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 2] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 8] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 3] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 1] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 7] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 6] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 0] round 3 fit, config: {'server_round': 3, 'local_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-04-02 15:35:24,368 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
      "INFO flwr 2024-04-02 15:35:24,735 | server.py:125 | fit progress: (3, 2.303821851730347, {'accuracy': 8.3984375}, 68.2505871958565)\n",
      "DEBUG flwr 2024-04-02 15:35:24,735 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 3: evaluation loss 2.303821851730347 | accuracy 8.3984375\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1039175)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-04-02 15:35:30,798 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
      "INFO flwr 2024-04-02 15:35:30,798 | server.py:153 | FL finished in 74.313835040899\n",
      "INFO flwr 2024-04-02 15:35:30,799 | app.py:226 | app_fit: losses_distributed [(1, 2.304241261291504), (2, 2.3035378883361814), (3, 2.303084147262573)]\n",
      "INFO flwr 2024-04-02 15:35:30,799 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-04-02 15:35:30,799 | app.py:228 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2024-04-02 15:35:30,799 | app.py:229 | app_fit: losses_centralized [(0, 2.3042768020629882), (1, 2.3041712799072265), (2, 2.303984405517578), (3, 2.303821851730347)]\n",
      "INFO flwr 2024-04-02 15:35:30,800 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 8.3984375), (1, 8.3984375), (2, 8.3984375), (3, 8.3984375)]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.304241261291504\n",
       "\tround 2: 2.3035378883361814\n",
       "\tround 3: 2.303084147262573\n",
       "History (loss, centralized):\n",
       "\tround 0: 2.3042768020629882\n",
       "\tround 1: 2.3041712799072265\n",
       "\tround 2: 2.303984405517578\n",
       "\tround 3: 2.303821851730347\n",
       "History (metrics, centralized):\n",
       "{'accuracy': [(0, 8.3984375), (1, 8.3984375), (2, 8.3984375), (3, 8.3984375)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Start The Training\n",
    "\n",
    "# client resources (allocate cpus and gpus)\n",
    "client_resources = {'num_cpus': NUM_WORKER//NUM_CLIENT, 'num_gpus': 1 if torch.cuda.is_available() else 0}\n",
    "\n",
    "# start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENT,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
