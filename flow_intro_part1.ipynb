{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 2.2.1+cu121 and Flower 1.7.0\n"
     ]
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Dict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started With Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "\n",
    "NUM_CLIENT = 10\n",
    "EPOCHS_CLIENT = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKER = cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Loading Federated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading The Federated Dataset ###\n",
    "\n",
    "# first split (into train and test) and then you partition a specific split (train or test), ex: train split partitioned into 10 IID partitions\n",
    "\n",
    "def load_fd_datasets(dataset_name: str):\n",
    "    # loading a federated dataset\n",
    "    federated_dataset = FederatedDataset(\n",
    "        dataset=dataset_name, # ex: 'cifar10'\n",
    "        # partitioners: in how many partitions you want your splits to be\n",
    "        partitioners={'train': NUM_CLIENT}\n",
    "        )\n",
    "\n",
    "    # batch-wise transformation function\n",
    "    def batch_transform(batch):\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        # transform batch data\n",
    "        batch['img'] = [img_transform(img) for img in batch['img']]\n",
    "        return batch\n",
    "    \n",
    "    # create train and val dataloaders\n",
    "    train_dataloaders = []\n",
    "    val_dataloaders = []\n",
    "\n",
    "    # wrap partitions (Datasets) into torch Dataloaders\n",
    "    for client_id in range(NUM_CLIENT):\n",
    "        # load the partition specified by the idx in the selected split\n",
    "        partition = federated_dataset.load_partition(node_id=client_id, split='train')\n",
    "        # pass the tranform function\n",
    "        partition = partition.with_transform(batch_transform)\n",
    "        # now break the partition into train & val datasets\n",
    "        partition = partition.train_test_split(train_size=0.8)\n",
    "        # wrap with torch dataloader and add to dataloader list\n",
    "        partition_train_dl = DataLoader(\n",
    "            dataset=partition['train'],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKER\n",
    "        )\n",
    "        partition_val_dl = DataLoader(\n",
    "            dataset=partition['test'],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKER\n",
    "        )\n",
    "        train_dataloaders.append(partition_train_dl)\n",
    "        val_dataloaders.append(partition_val_dl)\n",
    "        \n",
    "    # create test dataloader from the test split (Dataset) with transform function\n",
    "    test_data = federated_dataset.load_full(split='test').with_transform(batch_transform)\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKER\n",
    "    )\n",
    "\n",
    "    # return all the train (partitioned), val (partitioned) & test dataloaders\n",
    "    return train_dataloaders, val_dataloaders, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders, val_dataloaders, test_dataloader = load_fd_datasets(dataset_name='cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batch size 125\n",
      "train dataset size 4000\n",
      "val batch size 32\n",
      "val dataset size 1000\n",
      "test batch size 313\n",
      "test dataset size 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'train batch size {len(train_dataloaders[0])}')\n",
    "print(f'train dataset size {len(train_dataloaders[0].dataset)}')\n",
    "\n",
    "print(f'val batch size {len(val_dataloaders[0])}')\n",
    "print(f'val dataset size {len(val_dataloaders[0].dataset)}')\n",
    "\n",
    "print(f'test batch size {len(test_dataloader)}')\n",
    "print(f'test dataset size {len(test_dataloader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz0ElEQVR4nO3de3DW9Z3//dd1TkLOBHKQcEZQEfZeqjRjtSosB/d2pbI79jCz2G11tOBUabct3bZqDxPX3mttuxR3Z7vSztRD3bvoXbfVbbHEsQtYUIqnpUCpgJAgSBJyuK5ch8/9hz/TTUH9vCHhk8TnY+aaIcmbdz7f63t458p1Xa9EnHNOAACcZdHQCwAAvDcxgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMICAIXDHHXcoEomEXgYwrDGAAABBMIAAAEEwgAAAQTCAgDP0zDPP6KKLLlJRUZGmTZumf/mXfzmpJpfL6Wtf+5qmTZumVCqlyZMn64tf/KIymcyAukKhoDvuuEMNDQ0qKSnRFVdcoZdfflmTJ0/W9ddff5a2CDg74qEXAIxkL7zwghYtWqRx48bpjjvuUC6X0+23367a2toBdZ/85Cf1gx/8QH/913+tz3zmM9q6dauam5v1yiuvaMOGDf11a9as0d13362rr75aixcv1m9/+1stXrxY6XT6bG8aMPQcgNO2bNkyV1RU5F599dX+z7388ssuFou5t06vHTt2OEnuk5/85ID/+9nPftZJck899ZRzzrnW1lYXj8fdsmXLBtTdcccdTpJbsWLF0G4McJbxKzjgNOXzeT355JNatmyZJk6c2P/58847T4sXL+7/+Gc/+5kkafXq1QP+/2c+8xlJ0n/+539KkjZu3KhcLqdPfepTA+puueWWIVk/EBoDCDhNr7/+unp7ezVjxoyTvjZz5sz+f7/66quKRqOaPn36gJq6ujpVVlbq1Vdf7a+TdFJddXW1qqqqBnv5QHAMIOAs4Y2pwEAMIOA0jRs3TsXFxdq9e/dJX9u1a1f/vydNmqRCoXBSXVtbm9rb2zVp0qT+Oknas2fPgLpjx47p+PHjg718IDgGEHCaYrGYFi9erEcffVT79+/v//wrr7yiJ598sv/jq666SpJ07733Dvj/99xzjyTpL//yLyVJCxYsUDwe17p16wbU/fM///NQLB8IjpdhA2fgzjvv1BNPPKFLL71Un/rUp5TL5fTd735XF1xwgXbu3ClJmjt3rlasWKF//dd/VXt7uz74wQ/q2Wef1Q9+8AMtW7ZMV1xxhSSptrZWn/70p/VP//RP+qu/+istWbJEv/3tb/Xzn/9cNTU1/AoPo0/ol+EBI11LS4ubN2+eSyaTburUqe6+++5zt99+u/vfp1c2m3V33nmnmzJlikskEq6xsdGtWbPGpdPpAb1yuZz78pe/7Orq6lxxcbG78sor3SuvvOLGjh3rbrrpprO9acCQijjnXOghCODttbe3q6qqSl//+tf1D//wD6GXAwwangMChpHe3t6TPvfWc0eXX3752V0MMMR4DggYRh5++GGtX79eV111lUpLS/XMM8/owQcf1KJFi3TJJZeEXh4wqBhAwDAyZ84cxeNx3X333ers7Ox/YcLXv/710EsDBh3PAQEAguA5IABAEAwgAEAQw+45oEKhoEOHDqmsrIw33gHACOSc04kTJ9TQ0KBo9O0f5wy7AXTo0CE1NjaGXgYA4AwdOHBAEyZMeNuvD7sBVFZWJkm6755bVVyc8vo/8aj/I6VC3viai3zBuzQWjZla53L+vfMF/1pJisn/PknGbI80W493mepfbc161xaXlZt6V6T6vGsnN4wx9VbW/1hJGB+tW3/3nTMctsVFRabez/3usHdte4/t/Jk/o867tiTif5xItnM59g4/hZ9KUTJhqs/lcv61xktQIuG/loLLm3ofTCe9aw8bTvt0Oq1v3PWN/uv52xmyAbR27Vp985vfVGtrq+bOnavvfve7uvjii9/1/731a7fi4pRKvAeQ/8FVMAwUSQygUyjutV0oUin//kUpv33eX1/k39v3eOoX979SJCO2C1xUtquQYRaqxDiAilL+F6GU8Qe4kmL/tYyJ2M4fy7lsPTffKwOoJOK/74v8N7Hfuz2NMiQvQnj44Ye1evVq3X777Xruuec0d+5cLV68WEeOHBmKbwcAGIGGZADdc889uuGGG/Txj39c559/vu677z6VlJTo3//930+qzWQy6uzsHHADAIx+gz6A+vr6tH37di1cuPCP3yQa1cKFC7V58+aT6pubm1VRUdF/4wUIAPDeMOgD6OjRo8rn86qtrR3w+draWrW2tp5Uv2bNGnV0dPTfDhw4MNhLAgAMQ8FfBZdKpZQyPvEMABj5Bv0RUE1NjWKxmNra2gZ8vq2tTXV1/i/JBACMboM+gJLJpObNm6eNGzf2f65QKGjjxo1qamoa7G8HABihhuRXcKtXr9aKFSv0vve9TxdffLHuvfdedXd36+Mf//hQfDsAwAg0JAPouuuu0+uvv66vfOUram1t1Z/92Z/piSeeOOmFCe8kOrlM0TF+b2KLRf3fqBUzvgmsYPhrFbGY7c1uScMb76xvMIsZ3pmfiNsOg4MbXzDVv97u/xbqixsaTL1rzxnrXRsZa3vAn0373+fxeLGpdzxpfONqtse7du9rJ/9V1XdyuMvwpuW47fna7Pjx/sVjbW9wLkr4v4kyYj3vjW+4zecNb0Qt+Kd3SFLa8IbbaMR2Lo+N+F87izL++6fH83AdshchrFq1SqtWrRqq9gCAEY4/xwAACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAgi+J9jeDuRaEaRqF9ESCFqifDwjx2RpKgh5seQfvNmfdQ/7iPi/OM4JClXMEQI+W+iJCnrbFEvbW3+f+PpYIntTuw9Ue1dmyqtMPVWzP/06Os7YWpdNcYWaVNe7B/b9NyvbVFJ7Tn/3udOP9fUO5/0Pw57ErYonr64/zlhPTed9XwzxOXkC7beUUPEl3U74xH/uKnign/zQpFfLY+AAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEM2yy4TK5PsZxfnlAs6j9HnX801f/p7Z9PFYnY7k7LugsF/8ymN+tz3rWdXbYMrn37DpnqD79+1Ls2mUiaelec8M/VqhlnC8qy5IF1dLSbeu/6/W5TfV2Vf45dadKWM9c4sdG7Nm7s3Xb0de/aoly3qXcs4p+RVnD+54MkRaL+vSUpm/M/P/PGi5Bz/sdtNm/bznSmz7vWcglK92a86ngEBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIYthG8fRlehWL+0WhxA3xLdFIwrYQS3qL84+1kKSC/OM+XME/FkaSYgn/hR/Y7R+VI0k7n9tnqs/0+K89f9i2lnOc/yF86Girqfcbbxzzrk0kbKdSNG6r7+zyj6k5d+5MU+/i0lLv2uef+42p98z0RO/aC993jql3osw/QsrZknUkWeNy/OujMdu+LxT8e6f7bLFa2Zx/dE+mN+1d25vwWzOPgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBDNssuLzrU9755ZlFCv65Z9YcJidDjlneP1dJkiKGfLeIcVf1ZfLetTlbzJzKxpSb6rtP+GeqtXf410pSR8fr3rU9vb2m3hFDvlcyYcsYrKtrMNU3TpnqXWvJDpOkjnb/+3zyObWm3rPGN3rXVmfGmXofO37Eu7Z0ki0MLlpiOykiEf+f5SOWfElJkYj//iwrLTb1jkX9ryvZrH/OXE+XX24cj4AAAEEM+gC64447FIlEBtxmzZo12N8GADDCDcmv4C644AL98pe//OM3MUbPAwBGvyGZDPF4XHV1dUPRGgAwSgzJc0C7d+9WQ0ODpk6dqo997GPav3//29ZmMhl1dnYOuAEARr9BH0Dz58/X+vXr9cQTT2jdunXat2+fLr30Up04ceKU9c3NzaqoqOi/NTb6v2oGADByDfoAWrp0qf7mb/5Gc+bM0eLFi/Wzn/1M7e3t+vGPf3zK+jVr1qijo6P/duDAgcFeEgBgGBryVwdUVlbq3HPP1Z49e0759VQqpVQqNdTLAAAMM0P+PqCuri7t3btX9fX1Q/2tAAAjyKAPoM9+9rNqaWnRH/7wB/33f/+3PvShDykWi+kjH/nIYH8rAMAINui/gjt48KA+8pGP6NixYxo3bpw+8IEPaMuWLRo3zhazkYjFlfCMzYnH/bMtIhH/OAlJcoY4lmjUlrHhnH9cjjPE9khSLOYfPeJytuiW7p6Mqd4ZYkpyedv+iTj/+8X6q96uri7v2jGlpabe46vGmurLKmq8a7PGnyvLy/yjleIx2zHenfY/VsYU2fZPX7rCu7Zjb4+pd/kkW7RStLzPu9Z6jDsZrkER2yU9K/91Z3P+temsXxTPoA+ghx56aLBbAgBGIbLgAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBDPmfYzhdsXhc8bjf8mKWfCpb7JliMf9MqELB1jyfz/mvI2H7WSEZL/aufeNIu6l3Ot1rqs9l/fPAorJljV14/mzv2rFVVabeW7c/611bUlJi6l1izI7rTvtla0nS1EmTTb1Lx/gfK61tB029sxn/dXekJ5p6Tzyn2rt2x0u2v7Tc+QfbcVg6yXB+ltuuE5YYyLwxZ04R/7Vk84bcOM918AgIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABDEsI3iiUQSikR8Y3D856gzZvHk8/69IxFbfEcsnjT0tv2s0NnZ7V37u1deN/V2xjijMYaoFxliRySpu9c/5qe8zNb73OmzvGs7T7SbepeUVpjqE8ki79pew30iSdlc3rv2+LE3TL2nNIz3ro04284/0dnlXVtcbDgGJZ1I+8fOSNKY4/5RTJGU//0tSRn5xwhFo9ZLuv9aolH/61U06rcveQQEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACGLYZsHFYgnFYn7ZQ7FozLtvIW/Lm8rl/HO1YnHbPI/KPzsuFrUFsO3//RHv2taD7abeBWNmVzzqm+kn5XI5U+/f7d3lXXv02DFT77mz53rX9nT755JJUmdnu6m+unKsd+2efb8z9T5+3D8LcGy5f+aZJJ0o9c8Paz9qyyTMl6S8axNx26WuYAw8zBp2f1GXLZQwVtHrX2vMgnPOcO10lqxLv748AgIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEMWyz4PK5tPI5vzymaKzIu28i6p9NJUmJpGFGW8d5xP8/RCKWHCbpjdf9w6mOHrVlpOULtpysvmyfd20m7Z+9J0k11TXetcmE7XA/erTVu7a7t9vUu6io2FTf1+d/vxw9ZstUa+/0z/YrKrJlwaUz/vu+L5s29Y4ly71re3v889QkKRq1ncw5Q3ac6/a/XklSqqzUuzYSN2ZdFgz7J+9/DObyfn15BAQACMI8gJ5++mldffXVamhoUCQS0aOPPjrg6845feUrX1F9fb2Ki4u1cOFC7d69e7DWCwAYJcwDqLu7W3PnztXatWtP+fW7775b3/nOd3Tfffdp69atGjNmjBYvXqx02vbwGgAwupmfA1q6dKmWLl16yq8553TvvffqS1/6kq655hpJ0g9/+EPV1tbq0Ucf1Yc//OEzWy0AYNQY1OeA9u3bp9bWVi1cuLD/cxUVFZo/f742b958yv+TyWTU2dk54AYAGP0GdQC1tr75qqHa2toBn6+tre3/2p9qbm5WRUVF/62xsXEwlwQAGKaCvwpuzZo16ujo6L8dOHAg9JIAAGfBoA6guro6SVJbW9uAz7e1tfV/7U+lUimVl5cPuAEARr9BHUBTpkxRXV2dNm7c2P+5zs5Obd26VU1NTYP5rQAAI5z5VXBdXV3as2dP/8f79u3Tjh07VF1drYkTJ+rWW2/V17/+dc2YMUNTpkzRl7/8ZTU0NGjZsmWDuW4AwAhnHkDbtm3TFVdc0f/x6tWrJUkrVqzQ+vXr9bnPfU7d3d268cYb1d7erg984AN64oknVFRki5+IRaKKeUbVxGL+MTWRiC1GxvIg0RaCIcn5r9sZaiUpk/bfTkvMiyT1ZWzv6SqvqPKuLU2lTL0jhngQZ4hLkaTXjvjH62QzeVPvc+onmOqPt/vHJbW2Hjb1Tvf5H+NJ2fb95LoZ3rXFltgrSVFDPFVntzGKJ5Yw1ecyPd616S7bcZjKxLxr8zHbuVyQ/3HrDBc431rzALr88svf8USORCL66le/qq9+9avW1gCA95Dgr4IDALw3MYAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBmKN4zpZIJKlIxC8XLG/IKMoUbFlWEcNdFDfmRxmirNTXZ8sae+3g69612WyfqXchkjPVp9P+OVx140/9ZzveTrbXP4Orq8e278dX1HjXTj93uql3r7Ptz+d+u927trvXP8NOkor8o8ZM+1KSYvLPgovHbefPG28c967NpG0Zacliw50iqbPdfy2lpWWm3pky/8cJpWNMrZVK+P+HWMRwzOb9rps8AgIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABDFso3hcNCIX9cuqcXLefaNRW8RGLGaI4okWm3o7+UdbdHYcNfU++rp/fV/GFsUTT9h+bunu8Y/LaevwjzSRpJJU0rs2lvCLdnrLrHNnedeOKbbt+2efedpUv+/gH7xri4qKTL2zSf/7sKyswtS7bEypf3HMtn+On/A/xmNx/22UpO5eW2xTT9q/Ppa0RQ79bnund+2FqVpT73Hn+OeB+V6PJSnmWcsjIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQwzYLTor8n9u7yxdy3l0Lef9aSXKu4F8cNc5zQ33U2DtiKvfPeJKkQsE/e0+SCnn/zLuj7cYsuDH+uWdVlVWm3n842uZde+DAAVPvg62vmepjhv2fy9qO8WzMf/+Xl9jy2sZWVXrX9mYN55qkjp5e79ryclsWXMFlTfUyZEYeNBxXkvTU0zv8ex9pNPX+i2VzvWurakq8awsFsuAAAMMYAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABDEsI3i6UtnFYv5zcfilH8ci5KGWkmRiH9MScES2yOpkPOPqCkqse2q6rHl3rXJpK13NmeLKfHcjZKkaMR2H/b1ZLxrD3e3mnrv/71/vE7B2eKJTBFPkuT8j8OI/I8rSUrG/M+J8ZVlpt5Fcf+d39HRbuptOa4ymR5T786ublN9aekY79pJU8bbev/Ov7bl6e2m3pHimHftwqWzvWt7e9JedTwCAgAEwQACAARhHkBPP/20rr76ajU0NCgSiejRRx8d8PXrr79ekUhkwG3JkiWDtV4AwChhHkDd3d2aO3eu1q5d+7Y1S5Ys0eHDh/tvDz744BktEgAw+phfhLB06VItXbr0HWtSqZTq6upOe1EAgNFvSJ4D2rRpk8aPH6+ZM2fq5ptv1rFjx962NpPJqLOzc8ANADD6DfoAWrJkiX74wx9q48aN+sd//Ee1tLRo6dKlyr/NX8Vsbm5WRUVF/62x0fYX/QAAI9Ogvw/owx/+cP+/L7zwQs2ZM0fTpk3Tpk2btGDBgpPq16xZo9WrV/d/3NnZyRACgPeAIX8Z9tSpU1VTU6M9e/ac8uupVErl5eUDbgCA0W/IB9DBgwd17Ngx1dfXD/W3AgCMIOZfwXV1dQ14NLNv3z7t2LFD1dXVqq6u1p133qnly5errq5Oe/fu1ec+9zlNnz5dixcvHtSFAwBGNvMA2rZtm6644or+j996/mbFihVat26ddu7cqR/84Adqb29XQ0ODFi1apK997WtKpVKm75PN9yqe98vLiuX9c7hiLmFaRzTqX29LA5MKBf/MrkTKtu5zGmu9a+Nx22GQyfjnr0mSIU7P/JC8qqbCu7amZqyp92sHD3vXHj9ue/WmyxvuFEmuYMkktB2J1WUl3rUN1ZWm3oW8f27g8TeOm3rHEv7XlLYO2/7pSfeZ6itq/O/D+hlVpt5/vWKhd+3jD//a1Pu1A/u9a48ePce7Nt3rd40wD6DLL79c7h0O8CeffNLaEgDwHkQWHAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgiEH/e0CDJZUsUlHSL+spFjFshjGwLWIZ0c42zwsFv6w7SUoYcq8kqbau0rs2lbTlzJ04YSpXxBAG15v2z8eTpIghg62qxpbBVTXOP2euq6fb1DtrixpTUcx//58zzpZ5d0FjtX/vGv9aSerxj4JTW3uXqXfxmJh3bbbgXytJRQnbOZGqMBzjuV5T7xpDztxHP3mlqXemxz/XMVXsf53t7fa7/3gEBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIYthG8SQTJUomirxqYzH/mI1c3paBEo34984X0qbekYh/7Ewm22PqXVblv+6yilJT72Nv+MffSJIi/vlHkajtZ6LGSbXetZleW1zO/ldf967NZ20RQk7+0S2SVFUxxrt2yvhKU+/6qnLv2uKULRKqL++/7w8eOW7qXVbm37uhptLUu6Q4aaovrvK/lMZtKT/K9+X811Fqa15a5l/f1W04f2J+MWM8AgIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEMWyz4Lp6jikf8cudShWVePe1JXBJTlnv2rwxZy5mWI1z/nlQkjS22j/frbau0tT70ME3TPXZXMa71hgFp6v+6gPetVOn15t633PXQ961+/YdNPUuL/XPdpOk+uoq79qKMcWm3lUVY71rS8v9ayXpldeOeNe++tqrpt5V5f5ZfZXFM2y9aytN9fFS/yzAfNb/fJAk5/x7R/K2Eyhf8M/TU8FwDfKs5REQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACCIYRvFky/klc/7RVAU8v5xOfFY0rSOQsE/BiMqW+9k0r/eOf9tfHMt/saNrzD1ThUlTPVjYkXetbGYLSyp60SPd+3UGeeYer/v/bO9azvbu0y9p9TWmOpn1DV419ZU+EdTSVJ5dZ13bbstbUrPvvRb79pXW21xRnn5r/toZ6ep96RK/+gjSUoW+x+3mUy3qXc87n+dKBjjwPpyae/ajCFCKOMZv8UjIABAEAwgAEAQpgHU3Nysiy66SGVlZRo/fryWLVumXbt2DahJp9NauXKlxo4dq9LSUi1fvlxtbW2DumgAwMhnGkAtLS1auXKltmzZol/84hfKZrNatGiRurv/+DvN2267TT/96U/1yCOPqKWlRYcOHdK111476AsHAIxsphchPPHEEwM+Xr9+vcaPH6/t27frsssuU0dHh77//e/rgQce0JVXXilJuv/++3Xeeedpy5Ytev/7339Sz0wmo0zmj09YdRqfLAQAjExn9BxQR0eHJKm6ulqStH37dmWzWS1cuLC/ZtasWZo4caI2b958yh7Nzc2qqKjovzU2Np7JkgAAI8RpD6BCoaBbb71Vl1xyiWbPfvPlqq2trUomk6qsrBxQW1tbq9bW1lP2WbNmjTo6OvpvBw4cON0lAQBGkNN+H9DKlSv14osv6plnnjmjBaRSKaVSfn96GwAwepzWI6BVq1bp8ccf169+9StNmDCh//N1dXXq6+tTe3v7gPq2tjbV1fm/aQwAMPqZBpBzTqtWrdKGDRv01FNPacqUKQO+Pm/ePCUSCW3cuLH/c7t27dL+/fvV1NQ0OCsGAIwKpl/BrVy5Ug888IAee+wxlZWV9T+vU1FRoeLiYlVUVOgTn/iEVq9ererqapWXl+uWW25RU1PTKV8BBwB47zINoHXr1kmSLr/88gGfv//++3X99ddLkr71rW8pGo1q+fLlymQyWrx4sb73ve+ZF1ZcUq6SMX4ZYpb4sIhsWWOxqH8OUyxqfErNOe9Sa85cPOG/nZMn1pp6bx+zx1RfWeGfNXfhtBmm3vteOOxdu6XhRVPvaZP889eOT5tm6l1eUm6qr6oa612bStqOQ5cq9q79za6XTL1f2L3bu7ZQ8D8fJCkW9V93aZUt73BM1RhTvTNcSiNR/2xEScqb7hfb9S0S8V9LUcK/thD3y4IzHanO44JZVFSktWvXau3atZbWAID3GLLgAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQZz2n2MYagmXUsL5/ZkGS1JFJGKL+5Dzv4ucs83zTF+Xd20h32fqHY8nvGsnz7QllReNsW3nvtf2e9eWFfmvW5KOHfP/C7rP/j8vm3q/7zz/WKAJ42xxRjLGsYyp8u9fXlpq6l1U7n+Ml1TZLhmWc7OQz5l6ZzL+50Rt/XhT74qqMlN9POp/TsSL/COEJKkv22Oojpl6p+L+kUMukvWuLcT97g8eAQEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCGLZZcLFIVLGI33x0Lu3dty9nzFSL+ec2JYx3ZzLuX59zBVNv5f1DuOonVJtaX33txab6//fHLd61z//PS6be8UTEuzafs+VkFcX9M9XKq8aZeheMuYHFJf7ZcfsPHTD1ThzzP1ZSxqy+qqpy79rWw0dMvZ3y3rUVNbbsvWSJ7VzOFwznZ8H/eiVJEfn3drJlXeYL/jlzzrCOvDJedTwCAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEMWyjeLrTnSrE/OIcEkn/iJVk3BbHkor5R70oaovLyWX9YzOKE2NMvZ3LetdGI7Z1N116nqk+EvPfzv/vJ1tMvY+8fty79sLpM029Z02b4V3bm/OPhZGk4iJbNMzxzg7v2t++8rKp9+TJ53jXdhW6TL0LhogaS5qNJE2cUutdO36i7bwvuJyp3nCVkAyRNpIUjycN1bYonljUvz6X9b+mRCJ+9x+PgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBDNssuL6+vGJxv3wtQ0SRopGEaR0d+R7/2i7/Wkk6fvyEd21xypYdFov5/2wRjRtDuIyhXdX1Nd61i5a939T7wCv+WXAzxp1v6h03BHy90XbE1LuqstpU//uDB7xrGxsnmXrXjxvrXfvU1n2m3m8c6/SubaxvMPVe8n83edcWV9oudT1p/3VbOdlyA2NR/2tWPGJ7TJHp6/OuTafT3rW9PX45njwCAgAEYRpAzc3Nuuiii1RWVqbx48dr2bJl2rVr14Cayy+/XJFIZMDtpptuGtRFAwBGPtMAamlp0cqVK7Vlyxb94he/UDab1aJFi9Td3T2g7oYbbtDhw4f7b3ffffegLhoAMPKZfjH6xBNPDPh4/fr1Gj9+vLZv367LLrus//MlJSWqq6sbnBUCAEalM3oOqKPjzT+SVV098AnVH/3oR6qpqdHs2bO1Zs0a9fS8/ZPzmUxGnZ2dA24AgNHvtF8FVygUdOutt+qSSy7R7Nmz+z//0Y9+VJMmTVJDQ4N27typz3/+89q1a5d+8pOfnLJPc3Oz7rzzztNdBgBghDrtAbRy5Uq9+OKLeuaZZwZ8/sYbb+z/94UXXqj6+notWLBAe/fu1bRp007qs2bNGq1evbr/487OTjU2Np7usgAAI8RpDaBVq1bp8ccf19NPP60JEya8Y+38+fMlSXv27DnlAEqlUkqlUqezDADACGYaQM453XLLLdqwYYM2bdqkKVOmvOv/2bFjhySpvr7+tBYIABidTANo5cqVeuCBB/TYY4+prKxMra2tkqSKigoVFxdr7969euCBB3TVVVdp7Nix2rlzp2677TZddtllmjNnzpBsAABgZDINoHXr1kl6882m/9v999+v66+/XslkUr/85S917733qru7W42NjVq+fLm+9KUvDdqCAQCjg/lXcO+ksbFRLS0tZ7Sgt+x8uU3JoqRXbaHwzuv637pOGILjJLV3dPn37uo19U5n/HOYCnn/WklKJPxfYZ9M2p4KLEr57Ze35PJ+uVCSVBIvMfWuL/XPD+tN50y9O3KG/RONmXr3FWx5YIlS/3107oW2LLjuY/6ZhAf2Hzb1TsT9Mwz/7IILTL2rx/kf49Zst3Svf+6ZJCnmf07kCrZrkMv5Z0wm47ZzM2rIjMzk/M+fTM7v+CYLDgAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQxGn/PaChtm37XsUSfsuLRPz7GhNQ5AwxPwUVTL0j8u/tjAtPp/3XEo/bfg6JVZjKFXH+a+96wz+2R5L6avx3vovb4lUyff5RPKlksal3tMgWCxSN+Mc87Wndber92u9e964tKx1j6l1fM9a7dtaMiabeqZT/5SsXNVwkJJUW+0cISVLE0D+Xs0XxFAxLjydt57IzXIMSUf+Yn3jB7zzmERAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgiGGbBZfr65JzMa/aSMSvTpKiMdvMtWQ8RfL+uUqSFIkYcpiMGU9lpf5ZVhecV2/qPWVyrak+FU951+78zWum3rt3HvCuLSkuM/UuKyv1ro0lbVl955xbaaofk67yrn3194dMvTt6271rx4+3BQFOHDfOu3ZsvW3/ZCP+93nUFtMoybY/4y7hXZtI+GeqSVI+4X/uRy3BmJKyuR7v2kLEPxtREbLgAADDGAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQxLCN4olGo4pG/eZjzBBV4Qq2TI5C3r8+lbLdneXlxd61VdX+tZI0sbHSu3bG5AZT76KUf7SOJMWT/jElcy6eYOqdyfpFfkhSV7t/7IgkjWv0jzMaP8F2nzROLzfVT475R/FMm2y7D+fO7vWu7eroMvUuTfkft9V1/seJJJXE/CNtcoWsqbc1uccZUrhyxmuQYv7NLbFkkmRZSi7rv45czq+WR0AAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIIZtFlxDfaUSSb/llVf753AdbbNlWXV2+eeHjR9XaepdXGTIGqstNfUeU+afCZXJ2XKyFLH93JLt9b8Pi8bYMtUuWzLVfx3ZvKl3LO5/HyYT/vtSkqKGHDNJyjv/0K6S8jGm3uVV/vXRaK2ptytE/HsXbMdVLOGfHZfJ9Jl69+X8MwYlKRLxv5QWDPtSkpT3Pw4TMVsWXDzuv+8LOUNfzzoeAQEAgjANoHXr1mnOnDkqLy9XeXm5mpqa9POf/7z/6+l0WitXrtTYsWNVWlqq5cuXq62tbdAXDQAY+UwDaMKECbrrrru0fft2bdu2TVdeeaWuueYavfTSS5Kk2267TT/96U/1yCOPqKWlRYcOHdK11147JAsHAIxspueArr766gEff+Mb39C6deu0ZcsWTZgwQd///vf1wAMP6Morr5Qk3X///TrvvPO0ZcsWvf/97x+8VQMARrzTfg4on8/roYceUnd3t5qamrR9+3Zls1ktXLiwv2bWrFmaOHGiNm/e/LZ9MpmMOjs7B9wAAKOfeQC98MILKi0tVSqV0k033aQNGzbo/PPPV2trq5LJpCorKwfU19bWqrW19W37NTc3q6Kiov/W2Nho3ggAwMhjHkAzZ87Ujh07tHXrVt18881asWKFXn755dNewJo1a9TR0dF/O3DgwGn3AgCMHOb3ASWTSU2fPl2SNG/ePP3mN7/Rt7/9bV133XXq6+tTe3v7gEdBbW1tqqure9t+qVRKqZTtvR8AgJHvjN8HVCgUlMlkNG/ePCUSCW3cuLH/a7t27dL+/fvV1NR0pt8GADDKmB4BrVmzRkuXLtXEiRN14sQJPfDAA9q0aZOefPJJVVRU6BOf+IRWr16t6upqlZeX65ZbblFTUxOvgAMAnMQ0gI4cOaK//du/1eHDh1VRUaE5c+boySef1F/8xV9Ikr71rW8pGo1q+fLlymQyWrx4sb73ve+d1sL+/P+aqKJiv7iSbME/SibibL917Ojyz584bIz5SSZ6vWutMTKRmH/ERlW5qbWKUraol3jeP9YkErFtZzRqiMtJ2fZ93hAjk80b44kM94kk5XL+x2EyXmLrHXHetQVnyGORlIwX+/eWLaImbYi0SffaelsihCQpKv/7MGeM4onG/I/bTLrb1NsZzrdszj9SqzftF31kOiO///3vv+PXi4qKtHbtWq1du9bSFgDwHkQWHAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAhzGvZQc+7NSItM2j9eJ1fwjwfpy/j3laRc1r93wZawYYrvyPbZIlAs91+6xy824y29UWOMTMEQxRMduigeJ1u8iiWKJxIx7nyjXN5//+djtp8ro4a7peD8j1lJysX9m1ujeCKGfZ/ptR2zrmA7J6KGn+VzzniMxwxRSXnbum1RPP6937qmuHc5XiLu3SrOsoMHD/JH6QBgFDhw4IAmTJjwtl8fdgOoUCjo0KFDKisrUyTyx5+eOjs71djYqAMHDqi83JieOYKwnaPHe2EbJbZztBmM7XTO6cSJE2poaFA0+vaPDofdr+Ci0eg7Tszy8vJRvfPfwnaOHu+FbZTYztHmTLezoqLiXWt4EQIAIAgGEAAgiBEzgFKplG6//XalUqnQSxlSbOfo8V7YRontHG3O5nYOuxchAADeG0bMIyAAwOjCAAIABMEAAgAEwQACAATBAAIABDFiBtDatWs1efJkFRUVaf78+Xr22WdDL2lQ3XHHHYpEIgNus2bNCr2sM/L000/r6quvVkNDgyKRiB599NEBX3fO6Stf+Yrq6+tVXFyshQsXavfu3WEWewbebTuvv/76k/btkiVLwiz2NDU3N+uiiy5SWVmZxo8fr2XLlmnXrl0DatLptFauXKmxY8eqtLRUy5cvV1tbW6AVnx6f7bz88stP2p833XRToBWfnnXr1mnOnDn9aQdNTU36+c9/3v/1s7UvR8QAevjhh7V69Wrdfvvteu655zR37lwtXrxYR44cCb20QXXBBRfo8OHD/bdnnnkm9JLOSHd3t+bOnau1a9ee8ut33323vvOd7+i+++7T1q1bNWbMGC1evFjpdPosr/TMvNt2StKSJUsG7NsHH3zwLK7wzLW0tGjlypXasmWLfvGLXyibzWrRokXq7u7ur7ntttv005/+VI888ohaWlp06NAhXXvttQFXbeeznZJ0ww03DNifd999d6AVn54JEyborrvu0vbt27Vt2zZdeeWVuuaaa/TSSy9JOov70o0AF198sVu5cmX/x/l83jU0NLjm5uaAqxpct99+u5s7d27oZQwZSW7Dhg39HxcKBVdXV+e++c1v9n+uvb3dpVIp9+CDDwZY4eD40+10zrkVK1a4a665Jsh6hsqRI0ecJNfS0uKce3PfJRIJ98gjj/TXvPLKK06S27x5c6hlnrE/3U7nnPvgBz/oPv3pT4db1BCpqqpy//Zv/3ZW9+WwfwTU19en7du3a+HChf2fi0ajWrhwoTZv3hxwZYNv9+7damho0NSpU/Wxj31M+/fvD72kIbNv3z61trYO2K8VFRWaP3/+qNuvkrRp0yaNHz9eM2fO1M0336xjx46FXtIZ6ejokCRVV1dLkrZv365sNjtgf86aNUsTJ04c0fvzT7fzLT/60Y9UU1Oj2bNna82aNerp6QmxvEGRz+f10EMPqbu7W01NTWd1Xw67NOw/dfToUeXzedXW1g74fG1trf7nf/4n0KoG3/z587V+/XrNnDlThw8f1p133qlLL71UL774osrKykIvb9C1trZK0in361tfGy2WLFmia6+9VlOmTNHevXv1xS9+UUuXLtXmzZsVi/n/UbXholAo6NZbb9Ull1yi2bNnS3pzfyaTSVVWVg6oHcn781TbKUkf/ehHNWnSJDU0NGjnzp36/Oc/r127duknP/lJwNXavfDCC2pqalI6nVZpaak2bNig888/Xzt27Dhr+3LYD6D3iqVLl/b/e86cOZo/f74mTZqkH//4x/rEJz4RcGU4Ux/+8If7/33hhRdqzpw5mjZtmjZt2qQFCxYEXNnpWblypV588cUR/xzlu3m77bzxxhv7/33hhReqvr5eCxYs0N69ezVt2rSzvczTNnPmTO3YsUMdHR36j//4D61YsUItLS1ndQ3D/ldwNTU1isViJ70Co62tTXV1dYFWNfQqKyt17rnnas+ePaGXMiTe2nfvtf0qSVOnTlVNTc2I3LerVq3S448/rl/96lcD/m5XXV2d+vr61N7ePqB+pO7Pt9vOU5k/f74kjbj9mUwmNX36dM2bN0/Nzc2aO3euvv3tb5/VfTnsB1AymdS8efO0cePG/s8VCgVt3LhRTU1NAVc2tLq6urR3717V19eHXsqQmDJliurq6gbs187OTm3dunVU71fpzT87f+zYsRG1b51zWrVqlTZs2KCnnnpKU6ZMGfD1efPmKZFIDNifu3bt0v79+0fU/ny37TyVHTt2SNKI2p+nUigUlMlkzu6+HNSXNAyRhx56yKVSKbd+/Xr38ssvuxtvvNFVVla61tbW0EsbNJ/5zGfcpk2b3L59+9yvf/1rt3DhQldTU+OOHDkSemmn7cSJE+755593zz//vJPk7rnnHvf888+7V1991Tnn3F133eUqKyvdY4895nbu3OmuueYaN2XKFNfb2xt45TbvtJ0nTpxwn/3sZ93mzZvdvn373C9/+Uv353/+527GjBkunU6HXrq3m2++2VVUVLhNmza5w4cP9996enr6a2666SY3ceJE99RTT7lt27a5pqYm19TUFHDVdu+2nXv27HFf/epX3bZt29y+ffvcY4895qZOneouu+yywCu3+cIXvuBaWlrcvn373M6dO90XvvAFF4lE3H/91385587evhwRA8g557773e+6iRMnumQy6S6++GK3ZcuW0EsaVNddd52rr693yWTSnXPOOe66665ze/bsCb2sM/KrX/3KSTrptmLFCufcmy/F/vKXv+xqa2tdKpVyCxYscLt27Qq76NPwTtvZ09PjFi1a5MaNG+cSiYSbNGmSu+GGG0bcD0+n2j5J7v777++v6e3tdZ/61KdcVVWVKykpcR/60Ifc4cOHwy36NLzbdu7fv99ddtllrrq62qVSKTd9+nT393//966joyPswo3+7u/+zk2aNMklk0k3btw4t2DBgv7h49zZ25f8PSAAQBDD/jkgAMDoxAACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATx/wNf/0bcQ0FZ8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting an image and label of the first train partition in train dataloader\n",
    "batch = next(iter(train_dataloaders[0]))\n",
    "img, y = batch['img'][0].permute(1, 2, 0), batch['label'][0].item()\n",
    "# de-normalize image\n",
    "img = img / 2 + 0.5\n",
    "# get image label\n",
    "label = train_dataloaders[0].dataset.features['label'].int2str(y)\n",
    "# show image\n",
    "plt.imshow(img)\n",
    "plt.title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Centralized Training With Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 10, 16, 16]           --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 32, 32]           280\n",
       "│    └─ReLU: 2-2                         [1, 10, 32, 32]           --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 32, 32]           910\n",
       "│    └─ReLU: 2-4                         [1, 10, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 10, 16, 16]           --\n",
       "├─Sequential: 1-2                        [1, 10, 8, 8]             --\n",
       "│    └─Conv2d: 2-6                       [1, 10, 16, 16]           910\n",
       "│    └─ReLU: 2-7                         [1, 10, 16, 16]           --\n",
       "│    └─Conv2d: 2-8                       [1, 10, 16, 16]           910\n",
       "│    └─ReLU: 2-9                         [1, 10, 16, 16]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 10, 8, 8]             --\n",
       "├─Sequential: 1-3                        [1, 10]                   --\n",
       "│    └─Flatten: 2-11                     [1, 640]                  --\n",
       "│    └─Linear: 2-12                      [1, 10]                   6,410\n",
       "==========================================================================================\n",
       "Total params: 9,420\n",
       "Trainable params: 9,420\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.20\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.25\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Defining The Model ###\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Creates the TinyVGG architecture for 32*32 Image Data\"\"\"\n",
    "        \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= 10 * 8 * 8, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(self.block2(self.block1(x)))\n",
    "\n",
    "# create the model\n",
    "model = TinyVGG().to(DEVICE)\n",
    "summary(model, input_size=[1, 3, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Test Function ###\n",
    "### These function only work with FederatedDataset!!! (see batch loading is different) ###\n",
    "\n",
    "# calculate accuracy\n",
    "def accuracy_fn(y_pred: torch.tensor, y_true: torch.tensor) -> float:\n",
    "    \"\"\"Calculates the accuracy of a model on given predictions\n",
    "\n",
    "    Args:\n",
    "        y_pred: predicted labels\n",
    "        y_true: true labels\n",
    "    \n",
    "    Returns:\n",
    "        A float value which is the calculated accuracy.\n",
    "    \"\"\"\n",
    "    return ((torch.eq(y_pred, y_true).sum().item() / len(y_true)) * 100)\n",
    "\n",
    "# fit the model on training data\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "        (0.1112, 0.8743)\n",
    "    \"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    model.train() # model in train mode\n",
    "    for batch in data_loader:\n",
    "        # get data to device\n",
    "        X = batch['img'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        y_logit = model(X)\n",
    "        loss = loss_fn(y_logit, y)        \n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad() # empty param's grad\n",
    "        loss.backward() # backward propagation\n",
    "        optimizer.step() # updata params (take the gradient descent step)\n",
    "\n",
    "        # calculate loss and accuracy per batch\n",
    "        train_loss += loss.item() * len(y)\n",
    "        y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "        train_acc += accuracy_fn(y_pred_labels, y)\n",
    "\n",
    "    train_loss /= len(data_loader.dataset)\n",
    "    train_acc /= len(data_loader)\n",
    "    return (train_loss, train_acc)\n",
    "\n",
    "# test the model on test data\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "    a forward pass on a testing dataset.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        data_loader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    test_loss , test_acc = 0, 0\n",
    "\n",
    "    model.eval() # model in evaluation mode\n",
    "    with torch.inference_mode():\n",
    "        for batch in data_loader:\n",
    "            # get data to device\n",
    "            X = batch['img'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            \n",
    "            # forward pss\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)\n",
    "\n",
    "            # calculate loss and accuracy per batch\n",
    "            test_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            test_acc += accuracy_fn(y_pred_labels, y)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    test_acc /= len(data_loader)\n",
    "    return (test_loss, test_acc)\n",
    "\n",
    "# complete training function for given epochs\n",
    "def train_central(model: torch.nn.Module,\n",
    "          train_dl: torch.utils.data.DataLoader,\n",
    "          test_dl: torch.utils.data.DataLoader,\n",
    "          epochs,\n",
    "          device: torch.device,\n",
    "          loss_fn: torch.nn.Module = None,\n",
    "          optimizer: torch.optim.Optimizer = None) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained and tested.\n",
    "        train_dl: A DataLoader instance for the model to be trained on.\n",
    "        test_dl: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        epochs: An integer indicating how many epochs to train for.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in a list for \n",
    "        each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "                    train_acc: [...],\n",
    "                    test_loss: [...],\n",
    "                    test_acc: [...]} \n",
    "        For example if training for epochs=2: \n",
    "                    {train_loss: [2.0616, 1.0537],\n",
    "                    train_acc: [0.3945, 0.3945],\n",
    "                    test_loss: [1.2641, 1.5706],\n",
    "                    test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    \n",
    "    result = {'Train_Loss': [],\n",
    "            'Train_Acc': [],\n",
    "            'Test_Loss': [],\n",
    "            'Test_Acc': [],\n",
    "            }\n",
    "    \n",
    "    # optimizer and criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        trainlss, trainacc = train_step(model, train_dl, loss_fn, optimizer, device)\n",
    "\n",
    "        testlss, testacc = test_step(model, test_dl, loss_fn, device)\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss {trainlss:.4f} | Train Acc {trainacc:.2f} | Test Loss {testlss:.4f} | Test Acc {testacc:.2f}\")\n",
    "\n",
    "        result['Train_Loss'].append(trainlss)\n",
    "        result['Train_Acc'].append(trainacc)\n",
    "        result['Test_Loss'].append(testlss)\n",
    "        result['Test_Acc'].append(testacc)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def eval_central(model: torch.nn.Module,\n",
    "         data_loader: torch.utils.data.DataLoader,\n",
    "         device: torch.device,\n",
    "         loss_fn: torch.nn.Module = None) -> None:\n",
    "    \"\"\"\n",
    "    function to evaluate the model on testing data\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to fit the data.\n",
    "        data_loader (DataLoader): Iterable over the dataset.\n",
    "        loss_fn (nn.CrossEntropyLoss): Loss function.\n",
    "        accuracy_fn (accuracy_fn): Optimizer for gradient update.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    eval_loss , eval_acc = 0, 0\n",
    "\n",
    "    # criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in data_loader:\n",
    "            # get data to device\n",
    "            X = batch['img'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)\n",
    "\n",
    "            # calculate loss and accuracy per batch\n",
    "            eval_loss += loss.item()\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            eval_acc += accuracy_fn(y_pred_labels, y)\n",
    "\n",
    "    eval_loss /= len(data_loader)\n",
    "    eval_acc /= len(data_loader)\n",
    "    \n",
    "    result = {'model name': model.__class__.__name__,\n",
    "              'model loss': round(eval_loss, ndigits=3),\n",
    "              'model acc': round(eval_acc, ndigits=3)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19e8c758d764e74984929dadc246b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss 2.1663 | Train Acc 19.82 | Test Loss 1.9387 | Test Acc 28.32\n",
      "Epoch 1 | Train Loss 1.8226 | Train Acc 34.12 | Test Loss 1.7615 | Test Acc 36.23\n",
      "Epoch 2 | Train Loss 1.6548 | Train Acc 40.85 | Test Loss 1.6395 | Test Acc 42.19\n",
      "Epoch 3 | Train Loss 1.5682 | Train Acc 44.90 | Test Loss 1.6535 | Test Acc 40.82\n",
      "Epoch 4 | Train Loss 1.5051 | Train Acc 46.85 | Test Loss 1.6332 | Test Acc 42.38\n",
      "[INFO] evaluating model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model name': 'TinyVGG', 'model loss': 1.621, 'model acc': 41.384}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Centralized Training and Evaluation\n",
    "\n",
    "model = TinyVGG().to(DEVICE)\n",
    "# optimizer = torch.optim.SGD(params=model.parameters())\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# train\n",
    "print(f\"[INFO] training model\")\n",
    "result = train_central(model=model,\n",
    "                train_dl=train_dataloaders[0],\n",
    "                test_dl=val_dataloaders[0],\n",
    "                device=DEVICE,\n",
    "                epochs=5)\n",
    "\n",
    "# eval\n",
    "print(f\"[INFO] evaluating model\")\n",
    "eval_central(model, test_dataloader, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Federated Learning With FLOWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Test Function For FLOWER Clients\n",
    "### Train and Test Function ###\n",
    "\n",
    "# calculate accuracy\n",
    "def accuracy_fn(y_pred: torch.tensor, y_true: torch.tensor) -> float:\n",
    "    \"\"\"Calculates the accuracy of a model on given predictions\n",
    "\n",
    "    Args:\n",
    "        y_pred: predicted labels\n",
    "        y_true: true labels\n",
    "    \n",
    "    Returns:\n",
    "        A float value which is the calculated accuracy.\n",
    "    \"\"\"\n",
    "    return ((torch.eq(y_pred, y_true).sum().item() / len(y_true)) * 100)\n",
    "\n",
    "# fit the model on training data\n",
    "def train(model: torch.nn.Module,\n",
    "          data_loader: torch.utils.data.DataLoader,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          verbose=False,\n",
    "          loss_fn: torch.nn.Module = None,\n",
    "          optimizer: torch.optim.Optimizer = None) -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for the given epochs.\n",
    "\n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        epochs: Epochs.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        verbose: A boolean value to see the model metrics (loss and accuracy)\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    # optimizer and criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "    model.train() # model in train mode\n",
    "    total_epoch_loss, total_epoch_acc = 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            # get data to device\n",
    "            X = batch['img'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)        \n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad() # empty param's grad\n",
    "            loss.backward() # backward propagation\n",
    "            optimizer.step() # updata params (take the gradient descent step)\n",
    "\n",
    "            # Metrics\n",
    "            # calculate loss and accuracy per batch\n",
    "            train_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            train_acc += accuracy_fn(y_pred_labels, y)\n",
    "        \n",
    "        # per epoch\n",
    "        train_loss /= len(data_loader.dataset)\n",
    "        train_acc /= len(data_loader)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1} | Train Loss {train_loss:.4f} | Train Acc {train_acc:.2f}\")\n",
    "\n",
    "        # for all epochs\n",
    "        total_epoch_loss += train_loss\n",
    "        total_epoch_acc += train_acc\n",
    "    \n",
    "    return (total_epoch_loss / epochs, total_epoch_acc / epochs)\n",
    "    \n",
    "\n",
    "# test the model on test data\n",
    "def test(model: torch.nn.Module,\n",
    "         data_loader: torch.utils.data.DataLoader,\n",
    "         device: torch.device,\n",
    "         loss_fn: torch.nn.Module=None) -> Tuple[float, float]:\n",
    "    \"\"\"Tests a PyTorch model for the given epochs.\n",
    "\n",
    "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "    a forward pass on a testing dataset.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        data_loader: A DataLoader instance for the model to be tested on.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "        (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # criterion (loss_fn) if None given\n",
    "    if loss_fn == None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval() # model in evaluation mode\n",
    "    with torch.inference_mode():\n",
    "        for batch in data_loader:\n",
    "            # get data to device\n",
    "            X = batch['img'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            \n",
    "            # forward pss\n",
    "            y_logit = model(X)\n",
    "            loss = loss_fn(y_logit, y)\n",
    "\n",
    "            # calculate loss and accuracy per batch\n",
    "            test_loss += loss.item() * len(y)\n",
    "            y_pred_labels = torch.argmax(y_logit, dim=1)\n",
    "            test_acc += accuracy_fn(y_pred_labels, y)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    test_acc /= len(data_loader)\n",
    "    return (test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Updating Model Parameters (helper functions from client's perspective)\n",
    "\n",
    "# set client paramters\n",
    "def set_parameters(model: nn.Module, parameters: List[np.ndarray]):\n",
    "    # de-serialize the ndarray to tensors\n",
    "    parameters = [torch.from_numpy(np_arr).to(dtype=torch.float32, device=DEVICE) for np_arr in parameters]\n",
    "    # match every weight with its model block\n",
    "    param_dict = zip(model.state_dict().keys(), parameters)\n",
    "    # convert the param_dict to ordered dict and load back into the model\n",
    "    model.load_state_dict(OrderedDict(param_dict), strict=True)\n",
    "\n",
    "# get parameters from client\n",
    "def get_parameters(model: nn.Module) -> List[np.ndarray]:\n",
    "    # serialize the model weights into ndarray and return\n",
    "    return [weights.cpu().numpy() for _, weights in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing A FLOWER Client using NumPyClient\n",
    "\n",
    "class CustomClient(fl.client.NumPyClient):\n",
    "    \"\"\"A custom client implementation representing an organization with model and data\"\"\"\n",
    "\n",
    "    # pass a model, train and test dataloader\n",
    "    def __init__(self, model, train_dataloader, val_dataloader) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "\n",
    "    # return the current local model parameters to server\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.model)\n",
    "    \n",
    "    # receive global model parameters, train and return the updated parameters with other metrics\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = train(model=self.model, data_loader=self.train_dataloader, epochs=EPOCHS_CLIENT, device=DEVICE)\n",
    "        return get_parameters(self.model), len(self.train_dataloader), {'loss': loss, 'accuracy': accuracy} # updated parameters, num_batches, metrics\n",
    "    \n",
    "    # receive global model parameters, evaluate and return the metrics\n",
    "    def evaluate(self, parameters, config) -> Tuple[float | int | Dict[str, bool | bytes | float | int | str]]:\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = test(model=self.model, data_loader=self.val_dataloader, device=DEVICE)\n",
    "        return float(loss), len(self.val_dataloader), {'accuracy': accuracy} # loss, num_batches, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the Virtual Client Engine\n",
    "\n",
    "# client_fun: To create CustomClient instance on demand when requested from FLOWER Framework\n",
    "\n",
    "def client_fn(client_id: str) -> CustomClient:\n",
    "    \"\"\"Create a FLOWER client representing a single organization\n",
    "\n",
    "    Creates an instance of CustomClient based on the client_id provided\n",
    "    to load client specific data partition.\n",
    "\n",
    "    Args:\n",
    "        client_id: An str to load a specific client.\n",
    "\n",
    "    Returns:\n",
    "        A CustomClient (fl.client.NumPyClient) instance representing a FLOWER client.\n",
    "    \"\"\"\n",
    "\n",
    "    # create an instance of the model\n",
    "    model = TinyVGG().to(DEVICE)\n",
    "\n",
    "    # load the client specific dataloaders\n",
    "    train_dl = train_dataloaders[int(client_id)]\n",
    "    val_dl = val_dataloaders[int(client_id)]\n",
    "\n",
    "    # create client instance, convert object to Client type and return\n",
    "    return CustomClient(model=model, train_dataloader=train_dl, val_dataloader=val_dl).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-03-22 10:44:40,932 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "2024-03-22 10:44:42,588\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-03-22 10:44:43,373 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'CPU': 16.0, 'object_store_memory': 7589041766.0, 'node:10.255.93.233': 1.0, 'memory': 15178083534.0}\n",
      "INFO flwr 2024-03-22 10:44:43,373 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-03-22 10:44:43,373 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "INFO flwr 2024-03-22 10:44:43,379 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "INFO flwr 2024-03-22 10:44:43,379 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-03-22 10:44:43,380 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-03-22 10:44:45,234 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-03-22 10:44:45,234 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-03-22 10:44:45,235 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-03-22 10:44:45,235 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:44:52,309 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:44:52,316 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:44:54,394 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:44:54,394 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:01,707 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:01,712 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:03,491 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:03,491 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:10,693 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:10,698 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:12,499 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:12,499 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:19,443 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:19,447 | server.py:173 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:21,361 | server.py:187 | evaluate_round 4 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:21,362 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:29,100 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-03-22 10:45:29,105 | server.py:173 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-03-22 10:45:30,991 | server.py:187 | evaluate_round 5 received 5 results and 0 failures\n",
      "INFO flwr 2024-03-22 10:45:30,992 | server.py:153 | FL finished in 45.756718224001816\n",
      "INFO flwr 2024-03-22 10:45:30,992 | app.py:226 | app_fit: losses_distributed [(1, 2.3026082134246826), (2, 2.3030288074493406), (3, 2.3028984222412108), (4, 2.3029538326263426), (5, 2.302737197113037)]\n",
      "INFO flwr 2024-03-22 10:45:30,992 | app.py:227 | app_fit: metrics_distributed_fit {'train_loss': [(1, 2.3031972312927245), (2, 2.3031129083633424), (3, 2.303028942298889), (4, 2.302945051574707), (5, 2.302859384918213)], 'train_accuracy': [(1, 10.03), (2, 10.03), (3, 10.0075), (4, 10.0125), (5, 10.0025)]}\n",
      "INFO flwr 2024-03-22 10:45:30,993 | app.py:228 | app_fit: metrics_distributed {'test_accuracy': [(1, 10.15625), (2, 9.5703125), (3, 9.5703125), (4, 9.74609375), (5, 10.078125)]}\n",
      "INFO flwr 2024-03-22 10:45:30,993 | app.py:229 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-03-22 10:45:30,993 | app.py:230 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.3026082134246826\n",
       "\tround 2: 2.3030288074493406\n",
       "\tround 3: 2.3028984222412108\n",
       "\tround 4: 2.3029538326263426\n",
       "\tround 5: 2.302737197113037\n",
       "History (metrics, distributed, fit):\n",
       "{'train_loss': [(1, 2.3031972312927245), (2, 2.3031129083633424), (3, 2.303028942298889), (4, 2.302945051574707), (5, 2.302859384918213)], 'train_accuracy': [(1, 10.03), (2, 10.03), (3, 10.0075), (4, 10.0125), (5, 10.0025)]}History (metrics, distributed, evaluate):\n",
       "{'test_accuracy': [(1, 10.15625), (2, 9.5703125), (3, 9.5703125), (4, 9.74609375), (5, 10.078125)]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Start The Training\n",
    "\n",
    "# aggregate the metrics received from all the client's evaluate function\n",
    "def eval_weighted_avg(metrics: List[Tuple[int, Metrics]]):\n",
    "    #  multiply accuracy with each client's number of samples / or is it batch size??\n",
    "    accuracies = [num_examples * m['accuracy'] for num_examples, m in metrics]\n",
    "    num_samples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # aggregate and return the custom metrics (weighted avg)\n",
    "    return {'test_accuracy': sum(accuracies) / sum(num_samples)}\n",
    "\n",
    "# aggregate the metrics received from all the client's fit function\n",
    "def fit_weighted_avg(metrics: List[Tuple[int, Metrics]]):\n",
    "    #  multiply accuracy with each client's number of samples / or is it batch size??\n",
    "    accuracies = [num_examples * m['accuracy'] for num_examples, m in metrics]\n",
    "    num_samples = [num_examples for num_examples, _ in metrics]\n",
    "    # for loss\n",
    "    losses = [num_examples * m['loss'] for num_examples, m in metrics]\n",
    "\n",
    "    # aggregate and return the custom metrics (weighted avg)\n",
    "    return {'train_loss': sum(losses) / sum(num_samples), 'train_accuracy': sum(accuracies) / sum(num_samples)}\n",
    "\n",
    "# pre-defined strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0, # C: fraction of client to choose for training\n",
    "    fraction_evaluate=0.5, # fraction of client to choose for evaluation\n",
    "    min_fit_clients=10, # minimum clients needed for training\n",
    "    min_evaluate_clients=5, # minimum clients needed for evaluation\n",
    "    min_available_clients=10, # wait till given client are available\n",
    "    evaluate_metrics_aggregation_fn=eval_weighted_avg, # aggregate the metrics of clients\n",
    "    fit_metrics_aggregation_fn=fit_weighted_avg, # aggregate the metrics of clients\n",
    ")\n",
    "\n",
    "# client resources (allocate cpus and gpus)\n",
    "client_resources = {'num_cpus': NUM_WORKER//NUM_CLIENT, 'num_gpus': 1 if torch.cuda.is_available() else 0}\n",
    "\n",
    "# start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENT,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
